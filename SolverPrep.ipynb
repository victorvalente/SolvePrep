{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JmY9viveG3JE_ZS9LeohgKr1whgqi_Zb",
      "authorship_tag": "ABX9TyPMgl0hQvhBcK7NDpRDG467",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorvalente/SolvePrep/blob/main/SolverPrep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik8AobXt7gMl",
        "outputId": "fcedba18-a928-4a40-b7f3-1b91ae66bf1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: airportsdata in /usr/local/lib/python3.11/dist-packages (20250224)\n"
          ]
        }
      ],
      "source": [
        "pip install airportsdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# solve_prep_utils.py\n",
        "\n",
        "import json\n",
        "from enum import Enum\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "from dataclasses import dataclass, field\n",
        "import random\n",
        "import re\n",
        "\n",
        "# External Libraries (ensure these are installed: geopy, requests, pandas, numpy, airportsdata)\n",
        "try:\n",
        "    import geopy\n",
        "    import geopy.distance\n",
        "    import requests\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import airportsdata\n",
        "except ImportError as e:\n",
        "    print(f\"Error importing libraries in solve_prep_utils: {e}\")\n",
        "    print(\"Please ensure pandas, numpy, geopy, requests, and airportsdata are installed.\")\n",
        "    # Or raise the error: raise\n",
        "\n",
        "# --- Problem Definitions ---\n",
        "class ProblemType(Enum):\n",
        "    TSP_FLIGHTS = 1\n",
        "    TSP_DRIVING_FUEL = 2\n",
        "    KNAPSACK_MOVING = 3\n",
        "    VRP_MANHATTAN = 4\n",
        "    FACILITY_LOCATION_SEATTLE = 5\n",
        "    NURSE_SCHEDULING_MGH = 6\n",
        "    PORTFOLIO_OPTIMIZATION = 7\n",
        "    TIMETABLING_CONFERENCE = 8\n",
        "    PROJECT_SCHEDULING_CONSTRUCTION = 9\n",
        "    NETWORK_DESIGN_WATER = 10\n",
        "    OTHER_HEURISTIC = 99 # Catch-all for recognized heuristic problems\n",
        "    UNKNOWN = 0\n",
        "\n",
        "# --- Data Structures ---\n",
        "@dataclass\n",
        "class Location:\n",
        "    name: str\n",
        "    address: Optional[str] = None\n",
        "    coords: Optional[Tuple[float, float]] = None\n",
        "    iata_code: Optional[str] = None\n",
        "\n",
        "@dataclass\n",
        "class ProblemContext:\n",
        "    \"\"\"Holds the state of the problem preparation.\"\"\"\n",
        "    original_description: str\n",
        "    identified_type: ProblemType = ProblemType.UNKNOWN\n",
        "    extracted_data: Dict[str, Any] = field(default_factory=dict)\n",
        "    missing_info: List[str] = field(default_factory=list)\n",
        "    user_questions: List[str] = field(default_factory=list)\n",
        "    is_confirmed: bool = False\n",
        "    requires_manual_data: bool = True\n",
        "\n",
        "# --- LLM Interaction Placeholders (Improved Logic) ---\n",
        "# --- LLM Interaction Placeholders (Improved Logic) ---\n",
        "\n",
        "def call_llm_categorize(description: str, possible_types: List[ProblemType]) -> ProblemType:\n",
        "    \"\"\"Placeholder: Calls LLM to categorize the problem description.\"\"\"\n",
        "    print(\"\\nStep 1.1: Entering LLM Categorization...\")\n",
        "    print(f\"  Analyzing Full Input Description (Length: {len(description)}):\")\n",
        "    print(f\"  '{description}'\")\n",
        "    desc_lower = description.lower()\n",
        "    result_type = ProblemType.OTHER_HEURISTIC # Default\n",
        "\n",
        "    # --- Improved Placeholder Rules ---\n",
        "    if \"visit\" in desc_lower and (\"cities\" in desc_lower or \"european cities\" in desc_lower or re.search(r'\\b(london|paris|berlin|rome|madrid|amsterdam|prague|vienna|budapest|barcelona)\\b', desc_lower)) and (\"fly\" in desc_lower or \"flight\" in desc_lower or \"airfare\" in desc_lower):\n",
        "        print(\"  [LLM Placeholder Rule Match] TSP_FLIGHTS keywords matched.\")\n",
        "        result_type = ProblemType.TSP_FLIGHTS\n",
        "    elif (\"road trip\" in desc_lower or \"driving distances\" in desc_lower) and (\"national parks\" in desc_lower or \"yellowstone\" in desc_lower):\n",
        "        print(\"  [LLM Placeholder Rule Match] TSP_DRIVING_FUEL keywords matched.\")\n",
        "        result_type = ProblemType.TSP_DRIVING_FUEL\n",
        "    elif (\"move items\" in desc_lower or \"knapsack\" in desc_lower or \"bin packing\" in desc_lower or \"furniture\" in desc_lower) and (\"truck\" in desc_lower or \"container\" in desc_lower):\n",
        "        print(\"  [LLM Placeholder Rule Match] KNAPSACK_MOVING keywords matched.\")\n",
        "        result_type = ProblemType.KNAPSACK_MOVING\n",
        "    elif (\"delivery service\" in desc_lower or \"vehicle routing\" in desc_lower) and (\"addresses\" in desc_lower or \"locations\" in desc_lower) and (\"drivers\" in desc_lower or \"trucks\" in desc_lower or \"vehicles\" in desc_lower):\n",
        "        print(\"  [LLM Placeholder Rule Match] VRP_MANHATTAN keywords matched.\")\n",
        "        result_type = ProblemType.VRP_MANHATTAN\n",
        "    elif (\"optimal locations\" in desc_lower or \"facility location\" in desc_lower) and (\"shops\" in desc_lower or \"stores\" in desc_lower or \"facilities\" in desc_lower):\n",
        "        print(\"  [LLM Placeholder Rule Match] FACILITY_LOCATION_SEATTLE keywords matched.\")\n",
        "        result_type = ProblemType.FACILITY_LOCATION_SEATTLE\n",
        "    elif (\"schedule\" in desc_lower or \"scheduling\" in desc_lower) and \"nurses\" in desc_lower and (\"shifts\" in desc_lower or \"ward\" in desc_lower):\n",
        "        print(\"  [LLM Placeholder Rule Match] NURSE_SCHEDULING_MGH keywords matched.\")\n",
        "        result_type = ProblemType.NURSE_SCHEDULING_MGH\n",
        "    elif (\"invest\" in desc_lower or \"portfolio\" in desc_lower) and (\"stocks\" in desc_lower or \"assets\" in desc_lower or \"etfs\" in desc_lower or \"bonds\" in desc_lower) and (\"returns\" in desc_lower or \"risk\" in desc_lower):\n",
        "        print(\"  [LLM Placeholder Rule Match] PORTFOLIO_OPTIMIZATION keywords matched.\")\n",
        "        result_type = ProblemType.PORTFOLIO_OPTIMIZATION\n",
        "    elif (\"conference\" in desc_lower or \"timetabling\" in desc_lower) and (\"sessions\" in desc_lower or \"courses\" in desc_lower or \"events\" in desc_lower) and (\"rooms\" in desc_lower or \"timeslots\" in desc_lower):\n",
        "        print(\"  [LLM Placeholder Rule Match] TIMETABLING_CONFERENCE keywords matched.\")\n",
        "        result_type = ProblemType.TIMETABLING_CONFERENCE\n",
        "    elif (\"construction sequence\" in desc_lower or \"project scheduling\" in desc_lower or \"building\" in desc_lower) and (\"tasks\" in desc_lower or \"activities\" in desc_lower):\n",
        "        print(\"  [LLM Placeholder Rule Match] PROJECT_SCHEDULING_CONSTRUCTION keywords matched.\")\n",
        "        result_type = ProblemType.PROJECT_SCHEDULING_CONSTRUCTION\n",
        "    elif (\"water distribution network\" in desc_lower or \"network design\" in desc_lower) and (\"pipe\" in desc_lower or \"pump\" in desc_lower or \"pressure\" in desc_lower):\n",
        "        print(\"  [LLM Placeholder Rule Match] NETWORK_DESIGN_WATER keywords matched.\")\n",
        "        result_type = ProblemType.NETWORK_DESIGN_WATER\n",
        "    else:\n",
        "        print(\"  [LLM Placeholder Rule Match] No specific rule matched. Defaulting to OTHER_HEURISTIC.\")\n",
        "\n",
        "    print(f\"  [LLM Placeholder] Final Categorization: {result_type.name}\")\n",
        "    print(\"Step 1.1: Exiting LLM Categorization.\")\n",
        "    return result_type\n",
        "\n",
        "def call_llm_extract_initial_data(problem_type: ProblemType, description: str) -> Dict:\n",
        "    \"\"\"Placeholder: Calls LLM to extract only the initial key parameters.\"\"\"\n",
        "    print(\"\\nStep 2.1: Entering LLM Initial Data Extraction...\")\n",
        "    print(f\"  Problem Type: {problem_type.name}\")\n",
        "    extracted_data = {}\n",
        "    # --- Improved Placeholder Logic ---\n",
        "    if problem_type == ProblemType.TSP_FLIGHTS:\n",
        "        # More robust city extraction, handling potential multi-word cities\n",
        "        cities = re.findall(r'\\b[A-Z][a-zA-Z]+\\b(?: \\b[A-Z][a-zA-Z]+\\b)*', description)\n",
        "        common_words = {\"I\", \"Find\", \"The\", \"My\", \"A\", \"And\", \"Between\", \"Order\", \"Fly\", \"Flying\", \"Them\", \"European\", \"Cities\", \"Efficient\", \"Total\", \"Airfare\", \"Travel\", \"Time\"}\n",
        "        cities = [city.strip(',.:;') for city in cities if city not in common_words and len(city)>2]\n",
        "        # Filter against known cities from example if possible\n",
        "        example_cities = [\"London\", \"Paris\", \"Berlin\", \"Rome\", \"Madrid\", \"Amsterdam\", \"Prague\", \"Vienna\", \"Budapest\", \"Barcelona\"]\n",
        "        found_cities = [c for c in cities if c in example_cities]\n",
        "        if found_cities: cities = found_cities\n",
        "        elif not cities: cities = [\"London\", \"Paris\", \"Berlin\"] # Fallback\n",
        "        print(f\"  [LLM Placeholder] Extracted/Defaulted Cities: {cities}\")\n",
        "        extracted_data['list_of_cities'] = list(dict.fromkeys(cities))\n",
        "\n",
        "    elif problem_type == ProblemType.TSP_DRIVING_FUEL:\n",
        "         # Extract park names more reliably\n",
        "         parks = re.findall(r'\\b[A-Z][a-zA-Z]*(?: [A-Z][a-zA-Z]*)*\\b(?=\\s*(?:National Park|Mountains|Canyon))|\\b(Yellowstone|Yosemite|Zion|Olympic|Glacier|Acadia|Teton)\\b', description)\n",
        "         parks = list(dict.fromkeys([p.strip() for p in parks if p and len(p) > 3])) # Unique and clean up\n",
        "         if not parks: parks = [\"Yellowstone\", \"Grand Canyon\", \"Yosemite\"] # Fallback\n",
        "         print(f\"  [LLM Placeholder] Extracted Parks/Locations: {parks}\")\n",
        "         extracted_data['list_of_locations'] = parks\n",
        "         mpg_match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*MPG', description, re.IGNORECASE) # Allow decimals, ignore case\n",
        "         if mpg_match: extracted_data['vehicle_mpg'] = float(mpg_match.group(1)); print(f\"  [LLM Placeholder] Extracted MPG: {extracted_data['vehicle_mpg']}\")\n",
        "         else: print(\"  [LLM Placeholder] Could not extract MPG.\")\n",
        "\n",
        "    elif problem_type == ProblemType.KNAPSACK_MOVING:\n",
        "         # Try to extract truck size if mentioned\n",
        "         truck_match = re.search(r'(\\d+)-foot U-Haul truck', description)\n",
        "         if truck_match: extracted_data['truck_info'] = f\"{truck_match.group(1)}-foot U-Haul\"; print(f\"  [LLM Placeholder] Extracted Truck Info: {extracted_data['truck_info']}\")\n",
        "         else: print(\"  [LLM Placeholder] No specific initial parameters extracted for Knapsack.\")\n",
        "\n",
        "    elif problem_type == ProblemType.VRP_MANHATTAN:\n",
        "         drivers_match = re.search(r'(\\d+)\\s*drivers', description); addresses_match = re.search(r'(\\d+)\\s*addresses', description)\n",
        "         if drivers_match: extracted_data['num_drivers'] = int(drivers_match.group(1)); print(f\"  [LLM Placeholder] Extracted Drivers: {extracted_data['num_drivers']}\")\n",
        "         if addresses_match: extracted_data['num_addresses_expected'] = int(addresses_match.group(1)); print(f\"  [LLM Placeholder] Expected Addresses: {extracted_data['num_addresses_expected']}\")\n",
        "\n",
        "    elif problem_type == ProblemType.FACILITY_LOCATION_SEATTLE:\n",
        "         shops_match = re.search(r'(\\d+)\\s*new\\s*(?:coffee shops|stores|facilities)', description)\n",
        "         distance_match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*miles\\s*apart', description)\n",
        "         if shops_match: extracted_data['num_new_shops'] = int(shops_match.group(1)); print(f\"  [LLM Placeholder] Extracted Num Shops: {extracted_data['num_new_shops']}\")\n",
        "         if distance_match: extracted_data['min_distance_miles'] = float(distance_match.group(1)); print(f\"  [LLM Placeholder] Extracted Min Distance (miles): {extracted_data['min_distance_miles']}\")\n",
        "\n",
        "    elif problem_type == ProblemType.NURSE_SCHEDULING_MGH:\n",
        "         nurses_match = re.search(r'(\\d+)\\s*nurses', description); shifts_match = re.search(r'(\\d+)\\s*shifts', description)\n",
        "         if nurses_match: extracted_data['num_nurses'] = int(nurses_match.group(1)); print(f\"  [LLM Placeholder] Extracted Num Nurses: {extracted_data['num_nurses']}\")\n",
        "         if shifts_match: extracted_data['num_shifts'] = int(shifts_match.group(1)); print(f\"  [LLM Placeholder] Extracted Num Shifts: {extracted_data['num_shifts']}\")\n",
        "\n",
        "    elif problem_type == ProblemType.PORTFOLIO_OPTIMIZATION:\n",
        "         amount_match = re.search(r'\\$(\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)', description) # Match dollar amounts\n",
        "         if amount_match: extracted_data['investment_amount'] = float(amount_match.group(1).replace(',', '')); print(f\"  [LLM Placeholder] Extracted Investment Amount: {extracted_data['investment_amount']}\")\n",
        "\n",
        "    elif problem_type == ProblemType.TIMETABLING_CONFERENCE:\n",
        "         sessions_match = re.search(r'(\\d+)\\s*sessions', description); rooms_match = re.search(r'(\\d+)\\s*rooms', description); days_match = re.search(r'(\\d+)\\s*days', description)\n",
        "         if sessions_match: extracted_data['num_sessions'] = int(sessions_match.group(1)); print(f\"  [LLM Placeholder] Extracted Num Sessions: {extracted_data['num_sessions']}\")\n",
        "         if rooms_match: extracted_data['num_rooms'] = int(rooms_match.group(1)); print(f\"  [LLM Placeholder] Extracted Num Rooms: {extracted_data['num_rooms']}\")\n",
        "         if days_match: extracted_data['num_days'] = int(days_match.group(1)); print(f\"  [LLM Placeholder] Extracted Num Days: {extracted_data['num_days']}\")\n",
        "\n",
        "    elif problem_type == ProblemType.PROJECT_SCHEDULING_CONSTRUCTION:\n",
        "         story_match = re.search(r'(\\d+)-story building', description)\n",
        "         if story_match: extracted_data['building_stories'] = int(story_match.group(1)); print(f\"  [LLM Placeholder] Extracted Building Stories: {extracted_data['building_stories']}\")\n",
        "\n",
        "    elif problem_type == ProblemType.NETWORK_DESIGN_WATER:\n",
        "         homes_match = re.search(r'(\\d+)\\s*homes', description)\n",
        "         if homes_match: extracted_data['num_homes'] = int(homes_match.group(1)); print(f\"  [LLM Placeholder] Extracted Num Homes: {extracted_data['num_homes']}\")\n",
        "\n",
        "    else: print(\"  [LLM Placeholder] No specific initial data extraction rules for this type.\")\n",
        "    print(f\"  Output Extracted Data: {extracted_data}\")\n",
        "    print(\"Step 2.1: Exiting LLM Initial Data Extraction.\")\n",
        "    return extracted_data\n",
        "\n",
        "def call_llm_identify_missing_manual(problem_type: ProblemType, current_data: Dict, auto_fetched_keys: List[str] = []) -> List[str]:\n",
        "    \"\"\"Placeholder: Identifies missing manual info based on problem type and current data.\"\"\"\n",
        "    print(\"\\nStep 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\")\n",
        "    print(f\"  Problem Type: {problem_type.name}\"); print(f\"  Current Keys: {list(current_data.keys())}\"); print(f\"  Auto Keys: {auto_fetched_keys}\")\n",
        "    missing_info = []\n",
        "    # --- Improved Placeholder Logic ---\n",
        "    if problem_type == ProblemType.TSP_FLIGHTS:\n",
        "        if 'flight_cost_matrix' not in current_data: missing_info.append(\"Flight Costs between City Pairs\") # Should have been auto-fetched\n",
        "        if 'flight_duration_matrix' not in current_data: missing_info.append(\"Flight Durations between City Pairs\") # Should have been auto-fetched\n",
        "        if 'airport_transfer_times_hours' not in current_data: missing_info.append(\"Airport Transfer Times per City\")\n",
        "        # Optional ones last\n",
        "        if 'travel_date_range' not in current_data: missing_info.append(\"Preferred travel date range (optional)\")\n",
        "        if 'airline_preferences' not in current_data: missing_info.append(\"Airline preferences (optional)\")\n",
        "\n",
        "    elif problem_type == ProblemType.TSP_DRIVING_FUEL:\n",
        "         if 'driving_distance_matrix_miles' not in current_data: missing_info.append(\"Driving Distances between Park Entrances/Locations\")\n",
        "         if 'route_elevation_data_source' not in current_data: missing_info.append(\"Elevation Data along Routes\")\n",
        "         if 'park_closure_info_source' not in current_data: missing_info.append(\"Seasonal Park Closures/Road Status\")\n",
        "\n",
        "    elif problem_type == ProblemType.KNAPSACK_MOVING:\n",
        "        if not current_data.get(\"item_list_dimensions_values\"): missing_info.append(\"List of items with dimensions (width, height, depth) and value\")\n",
        "        if not current_data.get(\"truck_dimensions\"): missing_info.append(\"Truck cargo dimensions (width, height, depth)\")\n",
        "\n",
        "    elif problem_type == ProblemType.VRP_MANHATTAN:\n",
        "         if not current_data.get(\"delivery_addresses_list\"): missing_info.append(\"List of Delivery Addresses\")\n",
        "         if not current_data.get(\"customer_delivery_time_windows\"): missing_info.append(\"Customer Delivery Time Windows\")\n",
        "         if 'real_time_traffic_data_source' not in current_data: missing_info.append(\"Real-time Traffic Data Source\")\n",
        "\n",
        "    elif problem_type == ProblemType.FACILITY_LOCATION_SEATTLE:\n",
        "         if 'population_density_data' not in current_data: missing_info.append(\"Population Density Data\")\n",
        "         if 'competitor_locations' not in current_data: missing_info.append(\"Competitor Locations\")\n",
        "         if 'commercial_real_estate_cost_data' not in current_data: missing_info.append(\"Commercial Real Estate Cost Data\")\n",
        "         if 'traffic_pattern_data' not in current_data: missing_info.append(\"Traffic Pattern Data\")\n",
        "         if 'target_geographic_area' not in current_data: missing_info.append(\"Target Geographic Area Definition (e.g., Seattle boundary)\") # Added\n",
        "\n",
        "    elif problem_type == ProblemType.NURSE_SCHEDULING_MGH:\n",
        "         if not current_data.get(\"nurse_list_qualifications_preferences\"): missing_info.append(\"List of Nurses with Qualifications/Preferences\")\n",
        "         if not current_data.get(\"ward_staffing_requirements_per_shift\"): missing_info.append(\"Ward Staffing Requirements per Shift\")\n",
        "         if not current_data.get(\"labor_regulations_consecutive_days\"): missing_info.append(\"Labor Regulations (Consecutive days, hours/week)\")\n",
        "\n",
        "    elif problem_type == ProblemType.PORTFOLIO_OPTIMIZATION:\n",
        "         if not current_data.get(\"list_of_potential_assets\"): missing_info.append(\"List of Potential Assets (Stocks, Bonds, ETFs)\")\n",
        "         if 'risk_level_preference' not in current_data: missing_info.append(\"Risk Level Preference\")\n",
        "         if 'diversification_rules' not in current_data: missing_info.append(\"Diversification Rules\")\n",
        "         if 'historical_asset_performance_data' not in current_data: missing_info.append(\"Historical Asset Performance Data (Prices/Returns)\")\n",
        "         if 'asset_sector_classifications' not in current_data: missing_info.append(\"Asset Sector Classifications\")\n",
        "         if 'asset_volatility_metrics' not in current_data: missing_info.append(\"Asset Volatility Metrics\")\n",
        "         if 'asset_correlation_data' not in current_data: missing_info.append(\"Asset Correlation Data\")\n",
        "\n",
        "    elif problem_type == ProblemType.TIMETABLING_CONFERENCE:\n",
        "         if not current_data.get(\"list_of_sessions_with_topics_speakers\"): missing_info.append(\"List of Sessions with Topics/Speakers\")\n",
        "         if not current_data.get(\"list_of_rooms_with_capacities\"): missing_info.append(\"List of Rooms with Capacities\")\n",
        "         if 'timeslots_per_day' not in current_data: missing_info.append(\"Timeslots per Day\")\n",
        "         if 'speaker_availability_constraints' not in current_data: missing_info.append(\"Speaker Availability Constraints\")\n",
        "         if 'topic_relationships_minimize_distance_conflict' not in current_data: missing_info.append(\"Topic Relationships (Minimize distance/conflict)\")\n",
        "         if 'predicted_attendance_per_session_optional' not in current_data: missing_info.append(\"Predicted Attendance per Session (Optional)\") # Added optional tag\n",
        "\n",
        "    elif problem_type == ProblemType.PROJECT_SCHEDULING_CONSTRUCTION:\n",
        "         if not current_data.get(\"list_of_tasks_with_durations_and_dependencies\"): missing_info.append(\"List of Tasks with Durations and Dependencies\")\n",
        "         if not current_data.get(\"crew_availability_type_and_count_per_period\"): missing_info.append(\"Crew Availability (Type and Count per Period)\")\n",
        "         if not current_data.get(\"material_delivery_lead_times\"): missing_info.append(\"Material Delivery Lead Times\")\n",
        "         if 'weather_forecast_source_data' not in current_data: missing_info.append(\"Weather Forecast Source/Data\")\n",
        "\n",
        "    elif problem_type == ProblemType.NETWORK_DESIGN_WATER:\n",
        "         if 'development_location_area_definition' not in current_data: missing_info.append(\"Development Location/Area Definition\")\n",
        "         if 'elevation_data_for_area' not in current_data: missing_info.append(\"Elevation Data for Area\")\n",
        "         if 'water_demand_patterns_per_home_area_peak_avg' not in current_data: missing_info.append(\"Water Demand Patterns (Per Home/Area, Peak/Avg)\")\n",
        "         if not current_data.get(\"pipe_types_and_costs_per_unit_length_per_diameter\"): missing_info.append(\"Pipe Types and Costs (Per unit length per diameter)\")\n",
        "         if not current_data.get(\"pump_types_and_costs_based_on_head_flow_capacity\"): missing_info.append(\"Pump Types and Costs (Based on head/flow capacity)\")\n",
        "         if 'minimum_pressure_requirements_at_nodes' not in current_data: missing_info.append(\"Minimum Pressure Requirements at Nodes\")\n",
        "         if 'hydraulic_simulation_library_tool' not in current_data: missing_info.append(\"Hydraulic Simulation Library/Tool\")\n",
        "\n",
        "    else: # OTHER_HEURISTIC or UNKNOWN\n",
        "        if not any(k not in ['list_of_cities', 'city_to_code', 'geocoded_locations'] + auto_fetched_keys for k in current_data):\n",
        "             missing_info.append(\"Specific problem parameters needing manual input\")\n",
        "\n",
        "    print(f\"  [LLM Placeholder] Identified missing manual info: {missing_info} (using improved rules)\")\n",
        "    print(\"Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\")\n",
        "    return missing_info\n",
        "\n",
        "def call_llm_generate_questions(missing_info: List[str]) -> List[str]:\n",
        "    \"\"\"Placeholder: Calls LLM to generate user-friendly questions.\"\"\"\n",
        "    print(\"\\nStep 4.2: Entering LLM Generate Questions...\")\n",
        "    print(f\"  Input Missing Info: {missing_info}\")\n",
        "    questions = []\n",
        "    for info in missing_info:\n",
        "        questions.append(f\"Could you please provide the '{info}'?\")\n",
        "    print(f\"  [LLM Placeholder] Generated questions: {questions} (using simple logic)\")\n",
        "    print(\"Step 4.2: Exiting LLM Generate Questions.\")\n",
        "    return questions\n",
        "\n",
        "# --- SolvePrep Class ---\n",
        "class SolvePrep:\n",
        "    \"\"\"Handles problem preparation using LLM and automatic data fetching where applicable.\"\"\"\n",
        "    # (Class definition remains exactly the same as the previous version)\n",
        "    def __init__(self, gemini_api_key: Optional[str] = None, flight_api_key: Optional[str] = None):\n",
        "        self.geolocator = None; self.airports_db = None\n",
        "        try: self.geolocator = geopy.Nominatim(user_agent=\"heuristic_solver_util_v1\")\n",
        "        except Exception as e: print(f\"  Warning: Failed to initialize geolocator: {e}\")\n",
        "        self.gemini_api_key = gemini_api_key; self.flight_api_key = flight_api_key\n",
        "        try: self.airports_db = airportsdata.load('IATA')\n",
        "        except Exception as e: print(f\"  Warning: Could not load airports database: {e}.\")\n",
        "\n",
        "    def _get_airport_codes(self, cities: List[str]) -> Dict[str, Optional[str]]:\n",
        "        print(\"\\nStep 2.2.1: Entering Airport Code Lookup...\"); print(f\"  Input Cities: {cities}\")\n",
        "        if not self.airports_db: print(\"  Error: Airports database not loaded.\"); return {c: None for c in cities}\n",
        "        city_to_code = {}\n",
        "        for city_name in cities:\n",
        "            found_code = None; print(f\"  Searching for city: '{city_name}'\")\n",
        "            try:\n",
        "                matches = [code for code, data in self.airports_db.items() if data.get('city', '').lower() == city_name.lower()]\n",
        "                if matches:\n",
        "                    if city_name == \"London\" and \"LHR\" in matches: found_code = \"LHR\"\n",
        "                    elif city_name == \"Paris\" and \"CDG\" in matches: found_code = \"CDG\"\n",
        "                    elif city_name == \"Berlin\" and \"BER\" in matches: found_code = \"BER\"\n",
        "                    elif city_name == \"Rome\" and \"FCO\" in matches: found_code = \"FCO\"\n",
        "                    elif city_name == \"Madrid\" and \"MAD\" in matches: found_code = \"MAD\"\n",
        "                    elif city_name == \"Amsterdam\" and \"AMS\" in matches: found_code = \"AMS\"\n",
        "                    elif city_name == \"Prague\" and \"PRG\" in matches: found_code = \"PRG\"\n",
        "                    elif city_name == \"Vienna\" and \"VIE\" in matches: found_code = \"VIE\"\n",
        "                    elif city_name == \"Budapest\" and \"BUD\" in matches: found_code = \"BUD\"\n",
        "                    elif city_name == \"Barcelona\" and \"BCN\" in matches: found_code = \"BCN\"\n",
        "                    else: found_code = matches[0]\n",
        "                    print(f\"    Found code(s): {matches} -> Selected: {found_code}\")\n",
        "                else: print(f\"    Code not found for city: '{city_name}'\")\n",
        "            except Exception as e: print(f\"    Error looking up code for '{city_name}': {e}\")\n",
        "            city_to_code[city_name] = found_code\n",
        "        print(f\"  Output City-to-Code Map: {city_to_code}\"); print(\"Step 2.2.1: Exiting Airport Code Lookup.\")\n",
        "        return city_to_code\n",
        "\n",
        "    def _fetch_flight_data(self, city_to_code: Dict[str, Optional[str]]) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:\n",
        "        print(\"\\nStep 2.2.2: Entering Flight Data Fetching (Placeholder)...\"); cities = list(city_to_code.keys()); codes = [city_to_code[city] for city in cities]; num_cities = len(cities)\n",
        "        print(f\"  Attempting to fetch data for {num_cities} cities with codes: {codes}\"); cost_matrix = np.full((num_cities, num_cities), np.inf); duration_matrix = np.full((num_cities, num_cities), np.inf)\n",
        "        np.fill_diagonal(cost_matrix, 0); np.fill_diagonal(duration_matrix, 0)\n",
        "        if not self.flight_api_key:\n",
        "            print(\"  Warning: Flight API key not provided.\"); print(\"  Generating dummy flight data instead.\")\n",
        "            for i in range(num_cities):\n",
        "                for j in range(i + 1, num_cities):\n",
        "                     cost = random.uniform(100, 1000); duration = random.uniform(1, 10)\n",
        "                     cost_matrix[i, j] = cost_matrix[j, i] = cost; duration_matrix[i, j] = duration_matrix[j, i] = duration\n",
        "                     print(f\"    Generated dummy data for route {cities[i]}-{cities[j]}: Cost={cost:.0f}, Dur={duration:.1f}h\")\n",
        "            print(\"Step 2.2.2: Exiting Flight Data Fetching (Dummy Data).\"); return cost_matrix, duration_matrix\n",
        "        valid_codes = [code for code in codes if code is not None]\n",
        "        if len(valid_codes) < 2: print(\"  Error: Need at least two valid airport codes.\"); print(\"Step 2.2.2: Exiting Flight Data Fetching (Error).\"); return None, None\n",
        "        print(f\"  [API Placeholder] Simulating API calls for {len(valid_codes)} airports...\")\n",
        "        for i in range(num_cities):\n",
        "            for j in range(i + 1, num_cities):\n",
        "                origin_code = codes[i]; dest_code = codes[j]\n",
        "                if origin_code and dest_code:\n",
        "                    print(f\"    [API Placeholder] Simulating API call for route: {origin_code} -> {dest_code}\")\n",
        "                    simulated_cost = random.uniform(100, 1000); simulated_duration = random.uniform(1, 10)\n",
        "                    cost_matrix[i, j] = cost_matrix[j, i] = simulated_cost; duration_matrix[i, j] = duration_matrix[j, i] = simulated_duration\n",
        "                    print(f\"      [API Placeholder] Simulated data: Cost={simulated_cost:.0f}, Dur={simulated_duration:.1f}h\")\n",
        "                else: print(f\"    Skipping route involving missing codes: {cities[i]} / {cities[j]}\")\n",
        "        print(\"  [API Placeholder] Flight data fetching simulation complete.\"); print(\"Step 2.2.2: Exiting Flight Data Fetching (Simulated API).\")\n",
        "        return cost_matrix, duration_matrix\n",
        "\n",
        "    def _update_data_based_on_answers(self, current_data: Dict, questions: List[str], answers: List[str]) -> Dict:\n",
        "        print(\"\\nStep 4.4: Entering Update Data Based on Answers...\"); print(f\"  Input Questions: {questions}\"); print(f\"  Input Answers: {answers}\")\n",
        "        for i, answer in enumerate(answers):\n",
        "            if i < len(questions):\n",
        "                question = questions[i].lower(); key_guess = f\"user_provided_{i}\"\n",
        "                match = re.search(r\"provide the '(.+?)'\", question)\n",
        "                if match:\n",
        "                    info_requested = match.group(1).lower()\n",
        "                    # --- Key Guessing Logic ---\n",
        "                    if \"list of items\" in info_requested: key_guess = \"item_list_dimensions_values\"\n",
        "                    elif \"truck cargo dimensions\" in info_requested: key_guess = \"truck_dimensions\"\n",
        "                    elif \"date range\" in info_requested: key_guess = \"travel_date_range\"\n",
        "                    elif \"airline preferences\" in info_requested: key_guess = \"airline_preferences\"\n",
        "                    elif \"airport transfer times\" in info_requested: key_guess = \"airport_transfer_times_hours\"\n",
        "                    elif \"driving distances\" in info_requested: key_guess = \"driving_distance_matrix_miles\"\n",
        "                    elif \"elevation data\" in info_requested: key_guess = \"route_elevation_data_source\"\n",
        "                    elif \"park closures\" in info_requested: key_guess = \"park_closure_info_source\"\n",
        "                    elif \"delivery addresses\" in info_requested: key_guess = \"delivery_addresses_list\"\n",
        "                    elif \"customer delivery time windows\" in info_requested: key_guess = \"customer_delivery_time_windows\"\n",
        "                    elif \"traffic data source\" in info_requested: key_guess = \"real_time_traffic_data_source\"\n",
        "                    elif \"population density\" in info_requested: key_guess = \"population_density_data\"\n",
        "                    elif \"competitor locations\" in info_requested: key_guess = \"competitor_locations\"\n",
        "                    elif \"real estate cost\" in info_requested: key_guess = \"commercial_real_estate_cost_data\"\n",
        "                    elif \"traffic pattern\" in info_requested: key_guess = \"traffic_pattern_data\"\n",
        "                    elif \"nurse list\" in info_requested: key_guess = \"nurse_list_qualifications_preferences\"\n",
        "                    elif \"ward staffing\" in info_requested: key_guess = \"ward_staffing_requirements_per_shift\"\n",
        "                    elif \"labor regulations\" in info_requested: key_guess = \"labor_regulations_consecutive_days\"\n",
        "                    elif \"list of potential assets\" in info_requested: key_guess = \"list_of_potential_assets\"\n",
        "                    elif \"risk level preference\" in info_requested: key_guess = \"risk_level_preference\"\n",
        "                    elif \"diversification rules\" in info_requested: key_guess = \"diversification_rules\"\n",
        "                    elif \"historical asset performance\" in info_requested: key_guess = \"historical_asset_performance_data\"\n",
        "                    elif \"sector classifications\" in info_requested: key_guess = \"asset_sector_classifications\"\n",
        "                    elif \"volatility metrics\" in info_requested: key_guess = \"asset_volatility_metrics\"\n",
        "                    elif \"correlation data\" in info_requested: key_guess = \"asset_correlation_data\"\n",
        "                    elif \"list of sessions\" in info_requested: key_guess = \"list_of_sessions_with_topics_speakers\"\n",
        "                    elif \"list of rooms\" in info_requested: key_guess = \"list_of_rooms_with_capacities\"\n",
        "                    elif \"timeslots per day\" in info_requested: key_guess = \"timeslots_per_day\"\n",
        "                    elif \"speaker availability\" in info_requested: key_guess = \"speaker_availability_constraints\"\n",
        "                    elif \"topic relationships\" in info_requested: key_guess = \"topic_relationships_minimize_distance_conflict\"\n",
        "                    elif \"predicted attendance\" in info_requested: key_guess = \"predicted_attendance_per_session_optional\"\n",
        "                    elif \"list of tasks\" in info_requested: key_guess = \"list_of_tasks_with_durations_and_dependencies\"\n",
        "                    elif \"crew availability\" in info_requested: key_guess = \"crew_availability_type_and_count_per_period\"\n",
        "                    elif \"material delivery\" in info_requested: key_guess = \"material_delivery_lead_times\"\n",
        "                    elif \"weather forecast\" in info_requested: key_guess = \"weather_forecast_source_data\"\n",
        "                    elif \"location/area definition\" in info_requested: key_guess = \"development_location_area_definition\"\n",
        "                    elif \"elevation data for area\" in info_requested: key_guess = \"elevation_data_for_area\"\n",
        "                    elif \"water demand patterns\" in info_requested: key_guess = \"water_demand_patterns_per_home_area_peak_avg\"\n",
        "                    elif \"pipe types and costs\" in info_requested: key_guess = \"pipe_types_and_costs_per_unit_length_per_diameter\"\n",
        "                    elif \"pump types and costs\" in info_requested: key_guess = \"pump_types_and_costs_based_on_head_flow_capacity\"\n",
        "                    elif \"minimum pressure requirements\" in info_requested: key_guess = \"minimum_pressure_requirements_at_nodes\"\n",
        "                    elif \"hydraulic simulation library\" in info_requested: key_guess = \"hydraulic_simulation_library_tool\"\n",
        "                    else: key_guess = info_requested.replace('(optional)', '').strip().replace(' ', '_').lower() # Fallback\n",
        "                    # --- End Key Guessing ---\n",
        "                print(f\"    Updating/Adding key '{key_guess}' with value '{answer}'\")\n",
        "                # Basic type conversion attempt\n",
        "                if (\"list\" in key_guess or \"constraints\" in key_guess or \"dimensions\" in key_guess or \"requirements\" in key_guess or \"preferences\" in key_guess or \"relationships\" in key_guess) and isinstance(answer, str) and '[' in answer and ']' in answer:\n",
        "                    try: current_data[key_guess] = json.loads(answer.replace(\"'\", '\"')); print(f\"      (Parsed as list/dict)\") ; continue\n",
        "                    except json.JSONDecodeError: print(f\"      (Could not parse answer as JSON list/dict, storing as string)\")\n",
        "                elif (\"matrix\" in key_guess or \"_data\" in key_guess or \"_source\" in key_guess) and isinstance(answer, str): print(f\"      (Storing potential file path/source as string)\") # Avoid parsing matrices\n",
        "                elif key_guess in [\"number_of_drivers_vehicles\", \"vehicle_mpg\", \"num_new_shops\", \"num_nurses\", \"num_shifts\", \"num_sessions\", \"num_rooms\", \"num_days\", \"building_stories\", \"num_homes\"] and isinstance(answer, str) and answer.isdigit():\n",
        "                     try: current_data[key_guess] = int(answer); print(f\"      (Parsed as int)\"); continue\n",
        "                     except ValueError: print(f\"      (Could not parse answer as int, storing as string)\")\n",
        "                elif isinstance(answer, str) and answer.replace('.','',1).isdigit():\n",
        "                     try: current_data[key_guess] = float(answer); print(f\"      (Parsed as float)\"); continue\n",
        "                     except ValueError: print(f\"      (Could not parse answer as float, storing as string)\")\n",
        "                current_data[key_guess] = answer\n",
        "            else: print(f\"    Warning: More answers ({len(answers)}) than questions ({len(questions)}).\")\n",
        "        print(f\"  Output Updated Data Keys: {list(current_data.keys())}\"); print(\"Step 4.4: Exiting Update Data Based on Answers.\")\n",
        "        return current_data\n",
        "\n",
        "    def _perform_geocoding_if_needed(self, problem_context: ProblemContext) -> None:\n",
        "        print(\"\\nStep 5: Entering Geocoding (if needed)...\")\n",
        "        if not self.geolocator: print(\"  Skipping geocoding, geolocator not initialized.\"); return\n",
        "        data = problem_context.extracted_data; loc_key = None\n",
        "        if \"delivery_addresses_list\" in data: loc_key = \"delivery_addresses_list\"\n",
        "        elif \"list_of_cities\" in data: loc_key = \"list_of_cities\"\n",
        "        elif \"list_of_locations\" in data: loc_key = \"list_of_locations\"\n",
        "        elif \"competitor_locations\" in data: loc_key = \"competitor_locations\" # Geocode competitor locs too?\n",
        "        elif \"development_location_area_definition\" in data: loc_key = \"development_location_area_definition\" # Maybe geocode single point?\n",
        "        elif \"user_provided_locations\" in data: loc_key = \"user_provided_locations\"\n",
        "        if loc_key and isinstance(data.get(loc_key), list):\n",
        "            if 'geocoded_locations' in data: print(\"  Skipping geocoding, already present.\")\n",
        "            else:\n",
        "                print(f\"  Attempting geocoding for locations in key: '{loc_key}'\"); geocoded_locations = []\n",
        "                locations_to_geocode = data[loc_key]; location_names = []\n",
        "                if locations_to_geocode:\n",
        "                     if isinstance(locations_to_geocode[0], dict) and 'name' in locations_to_geocode[0]: location_names = [loc.get('name', '') for loc in locations_to_geocode]; print(\"    (Extracting names from list of dicts)\")\n",
        "                     elif isinstance(locations_to_geocode[0], str): location_names = locations_to_geocode\n",
        "                     else: print(f\"    Warning: Cannot determine location names from format: {type(locations_to_geocode[0])}\")\n",
        "                else: print(\"    Warning: Location list is empty.\")\n",
        "                for loc_name in location_names:\n",
        "                    if isinstance(loc_name, str) and loc_name:\n",
        "                        print(f\"    Geocoding '{loc_name}'...\")\n",
        "                        try:\n",
        "                            location = self.geolocator.geocode(loc_name, timeout=10)\n",
        "                            if location: iata_code = data.get('city_to_code', {}).get(loc_name); geo_loc = Location(name=loc_name, address=location.address, coords=(location.latitude, location.longitude), iata_code=iata_code); geocoded_locations.append(geo_loc); print(f\"      Success: {geo_loc.coords}\" + (f\" (IATA: {iata_code})\" if iata_code else \"\"))\n",
        "                            else: print(f\"      Failed: Could not geocode.\"); geocoded_locations.append(Location(name=loc_name))\n",
        "                        except Exception as e: print(f\"      Error: {e}\"); geocoded_locations.append(Location(name=loc_name))\n",
        "                    else: print(f\"    Skipping invalid/empty location name: '{loc_name}'\")\n",
        "                data['geocoded_locations'] = geocoded_locations; print(\"  Geocoding complete.\")\n",
        "        # Handle single location geocoding if needed\n",
        "        elif loc_key and isinstance(data.get(loc_key), str):\n",
        "             loc_name = data[loc_key]\n",
        "             print(f\"    Geocoding single location '{loc_name}'...\")\n",
        "             # Similar try/except block as above for single location\n",
        "             try:\n",
        "                 location = self.geolocator.geocode(loc_name, timeout=10)\n",
        "                 if location: data['geocoded_location'] = Location(name=loc_name, address=location.address, coords=(location.latitude, location.longitude)); print(f\"      Success: {location.latitude, location.longitude}\")\n",
        "                 else: print(f\"      Failed: Could not geocode.\")\n",
        "             except Exception as e: print(f\"      Error: {e}\")\n",
        "\n",
        "        else: print(\"  No suitable location list/string found for geocoding or data type incorrect.\")\n",
        "        print(\"Step 5: Exiting Geocoding.\")\n",
        "\n",
        "    def present_data_for_confirmation(self, problem_context: ProblemContext, simulate: bool = False) -> bool:\n",
        "        print(\"\\nStep 6: Entering Present Data for Confirmation...\"); print(f\"  Identified Problem Type: {problem_context.identified_type.name}\"); print(\"  Collected & Prepared Data:\")\n",
        "        try: print(json.dumps(problem_context.extracted_data, indent=2, default=lambda o: repr(o)))\n",
        "        except Exception as e: print(f\"    Error converting data to JSON: {e}\"); print(f\"    Raw Data: {problem_context.extracted_data}\")\n",
        "        if simulate: print(\"  > Is the above problem formulation correct...?: yes (Simulated)\"); problem_context.is_confirmed = True\n",
        "        else: confirmation = input(\"  > Is the above problem formulation correct...? (yes/no): \"); problem_context.is_confirmed = confirmation.lower().strip() == 'yes'\n",
        "        print(f\"  User confirmation status: {problem_context.is_confirmed}\"); print(\"Step 6: Exiting Present Data for Confirmation.\")\n",
        "        return problem_context.is_confirmed\n",
        "\n",
        "    def run_preparation_pipeline(self, description: str, simulation_data: Optional[pd.DataFrame] = None) -> Optional[ProblemContext]:\n",
        "        print(\"\\nStarting Preparation Pipeline...\")\n",
        "        context = ProblemContext(original_description=description); is_simulation = simulation_data is not None\n",
        "        problem_type_map = {\n",
        "             ProblemType.TSP_FLIGHTS: \"Traveling Salesman Problem\", ProblemType.TSP_DRIVING_FUEL: \"TSP with constraints\",\n",
        "             ProblemType.KNAPSACK_MOVING: \"Knapsack/Bin Packing Problem\", ProblemType.VRP_MANHATTAN: \"Vehicle Routing Problem with Time Windows\",\n",
        "             ProblemType.FACILITY_LOCATION_SEATTLE: \"Facility Location Problem\", ProblemType.NURSE_SCHEDULING_MGH: \"Nurse Scheduling Problem\",\n",
        "             ProblemType.PORTFOLIO_OPTIMIZATION: \"Portfolio Optimization\", ProblemType.TIMETABLING_CONFERENCE: \"Timetabling Problem\",\n",
        "             ProblemType.PROJECT_SCHEDULING_CONSTRUCTION: \"Project Scheduling Problem\", ProblemType.NETWORK_DESIGN_WATER: \"Network Design Problem\",\n",
        "        }\n",
        "        print(\"\\n=== Step 1: Problem Categorization ===\"); context.identified_type = call_llm_categorize(description, list(ProblemType))\n",
        "        if context.identified_type == ProblemType.UNKNOWN: print(\"Pipeline Error: Could not identify problem type.\"); return None\n",
        "        print(f\"Pipeline Update: Problem categorized as {context.identified_type.name}\"); problem_type_str_for_sim = problem_type_map.get(context.identified_type, context.identified_type.name)\n",
        "\n",
        "        print(\"\\n=== Step 2: Initial Extraction / Automatic Data Fetching ===\"); context.extracted_data = call_llm_extract_initial_data(context.identified_type, description)\n",
        "        print(f\"Pipeline Update: Initial data extracted: {list(context.extracted_data.keys())}\"); auto_fetched_keys = []\n",
        "        if context.identified_type == ProblemType.TSP_FLIGHTS:\n",
        "            print(\"\\n--- Starting Automatic Flight Data Fetching ---\"); context.requires_manual_data = False; cities = context.extracted_data.get(\"list_of_cities\", [])\n",
        "            if not cities: print(\"Pipeline Error: City list needed for TSP_FLIGHTS.\"); return None\n",
        "            city_to_code = self._get_airport_codes(cities); context.extracted_data['city_to_code'] = city_to_code; print(f\"Pipeline Update: Stored city-to-code mapping.\")\n",
        "            valid_codes = [code for code in city_to_code.values() if code is not None]\n",
        "            if len(valid_codes) < len(cities): print(f\"Pipeline Warning: Found codes for {len(valid_codes)}/{len(cities)} cities.\");\n",
        "            if len(valid_codes) < 2: print(\"Pipeline Error: Need >= 2 valid codes.\"); return None\n",
        "            cost_matrix, duration_matrix = self._fetch_flight_data(city_to_code)\n",
        "            if cost_matrix is not None and duration_matrix is not None: print(\"Pipeline Update: Successfully fetched/simulated flight data.\"); context.extracted_data['flight_cost_matrix'] = cost_matrix; context.extracted_data['flight_duration_matrix'] = duration_matrix; auto_fetched_keys.extend(['flight_cost_matrix', 'flight_duration_matrix'])\n",
        "            else: print(\"Pipeline Error: Failed to fetch flight data.\"); return None\n",
        "            print(\"--- End Automatic Flight Data Fetching ---\")\n",
        "        elif context.identified_type == ProblemType.VRP_MANHATTAN: print(\"\\n--- Deferring Geocoding until after potential address list update ---\")\n",
        "        else: print(\"Pipeline Info: No automatic data fetching configured for this problem type in Step 2.\")\n",
        "\n",
        "        print(\"\\n=== Step 3 & 4: Manual Data Refinement / Simulation ===\"); context.missing_info = call_llm_identify_missing_manual(context.identified_type, context.extracted_data, auto_fetched_keys)\n",
        "        if context.missing_info: context.requires_manual_data = True; print(f\"Pipeline Info: Manual data required for: {context.missing_info}\")\n",
        "        else: context.requires_manual_data = False; print(\"Pipeline Info: No essential manual information identified as missing.\")\n",
        "\n",
        "        if context.requires_manual_data:\n",
        "            loop_name = \"Simulation\" if is_simulation else \"Manual Data Refinement\"; print(f\"\\n--- Starting {loop_name} Loop ---\")\n",
        "            for attempt in range(1):\n",
        "                print(f\"--- {loop_name} Attempt {attempt + 1} ---\"); context.user_questions = call_llm_generate_questions(context.missing_info)\n",
        "                if not context.user_questions: print(\"Pipeline Error: LLM failed to generate questions.\"); return None\n",
        "                user_answers = []\n",
        "                if is_simulation:\n",
        "                    print(\"Pipeline Action: Simulating answers based on requirements CSV...\"); current_missing_info = context.missing_info[:]\n",
        "                    for missing_item_desc in current_missing_info:\n",
        "                        sim_answer = f\"SimulatedData_NotFound_For_{missing_item_desc[:20]}\"; search_term = missing_item_desc.replace('(optional)','').strip().lower()\n",
        "                        matched_rows = simulation_data[(simulation_data['ProblemType'].str.lower() == problem_type_str_for_sim.lower()) & (simulation_data['RequiredInfoDescription'].str.lower().str.contains(search_term, na=False))]\n",
        "                        if not matched_rows.empty: sim_answer = matched_rows.iloc[0]['Format_Example']; print(f\"    Found sim data for '{missing_item_desc}': Using -> '{sim_answer}'\")\n",
        "                        else: print(f\"    Warning: No sim data found matching '{missing_item_desc}' for '{problem_type_str_for_sim}'.\")\n",
        "                        user_answers.append(sim_answer)\n",
        "                    print(f\"Pipeline Info: Simulated answers obtained: {user_answers}\")\n",
        "                else: print(\"Error: Manual input function (_get_user_input) is commented out.\"); return None\n",
        "                context.extracted_data = self._update_data_based_on_answers(context.extracted_data, context.user_questions, user_answers)\n",
        "                print(\"Pipeline Update: Data updated with answers.\"); context.missing_info = call_llm_identify_missing_manual(context.identified_type, context.extracted_data, auto_fetched_keys)\n",
        "                if not context.missing_info: print(\"Pipeline Info: All essential info seems gathered/simulated.\"); break\n",
        "            if context.missing_info: print(f\"Pipeline Error: Could not gather/simulate all required {loop_name} info.\"); print(f\"  Remaining: {context.missing_info}\"); return None\n",
        "            print(f\"--- End {loop_name} Loop ---\")\n",
        "        else: print(\"Pipeline Info: Skipping manual data refinement loop.\")\n",
        "\n",
        "        print(\"\\n=== Step 5: Post-Processing ===\"); self._perform_geocoding_if_needed(context)\n",
        "        print(\"\\n=== Step 6: Final Confirmation ===\");\n",
        "        if self.present_data_for_confirmation(context, simulate=is_simulation): print(\"\\nPreparation Pipeline Completed Successfully.\"); return context\n",
        "        else: print(\"\\nPreparation Pipeline Halted: Confirmation Failed.\"); return None\n",
        "\n",
        "print(\"SolvePrep Utils Defined.\")\n",
        "# --- End of solve_prep_utils.py ---"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WWKBB0f9-R9",
        "outputId": "2858552b-0aa6-455f-ddba-5a082725d3c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SolvePrep Utils Defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "jZLbzqB68o6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run_simulation.py\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from typing import Optional, List, Dict\n",
        "from tabulate import tabulate # Import tabulate for table generation\n",
        "\n",
        "# Import components from the utility file\n",
        "try:\n",
        "    from solve_prep_utils import SolvePrep, ProblemType, ProblemContext # Only import needed items\n",
        "    print(\"Successfully imported components from solve_prep_utils.py\")\n",
        "except ImportError as e:\n",
        "    print(f\"Error importing from solve_prep_utils.py: {e}\")\n",
        "    print(\"Ensure solve_prep_utils.py is in the same directory or Python path.\")\n",
        "    exit()\n",
        "except Exception as e: # Catch other potential errors during import\n",
        "    print(f\"An unexpected error occurred during import: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- Helper Functions for File IO (Moved Here) ---\n",
        "def read_problems_df_from_csv(filepath: str) -> Optional[pd.DataFrame]:\n",
        "    \"\"\"Reads all problem descriptions from a CSV file.\"\"\"\n",
        "    print(f\"\\nReading all problems from '{filepath}'...\")\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        if 'ProblemDescription' in df.columns:\n",
        "            print(f\"  Successfully read {len(df)} problems.\")\n",
        "            return df\n",
        "        else:\n",
        "            print(f\"  Error: CSV file must contain a 'ProblemDescription' column.\")\n",
        "            return None\n",
        "    except FileNotFoundError:\n",
        "        print(f\"  Error: CSV file not found at '{filepath}'.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"  Error reading CSV file: {e}\")\n",
        "        return None\n",
        "\n",
        "def load_simulation_data(filepath: str) -> Optional[pd.DataFrame]:\n",
        "     \"\"\"Loads the required info specifications for simulation.\"\"\"\n",
        "     print(f\"\\nLoading simulation answers/requirements from '{filepath}'...\")\n",
        "     try:\n",
        "          df = pd.read_csv(filepath)\n",
        "          required_cols = ['ProblemID', 'ProblemType', 'RequiredInfoDescription', 'Format_Example']\n",
        "          if all(col in df.columns for col in required_cols):\n",
        "               print(f\"  Successfully loaded simulation data ({len(df)} rows).\")\n",
        "               return df\n",
        "          else:\n",
        "               print(f\"  Error: Simulation CSV missing required columns. Expected: {required_cols}\")\n",
        "               return None\n",
        "     except FileNotFoundError:\n",
        "          print(f\"  Error: Simulation CSV file not found at '{filepath}'.\")\n",
        "          return None\n",
        "     except Exception as e:\n",
        "          print(f\"  Error reading simulation CSV file: {e}\")\n",
        "          return None\n",
        "\n",
        "# --- Function to Generate Analysis Table ---\n",
        "def generate_analysis_table(results: List[Dict]) -> str:\n",
        "     \"\"\"Formats the results list into a Markdown table.\"\"\"\n",
        "     headers = [\"Index\", \"Status\", \"Detected Type\", \"Issues/Notes\"]\n",
        "     table_data = []\n",
        "     for r in results:\n",
        "          index = r.get(\"index\", \"N/A\")\n",
        "          status = r.get(\"status\", \"Unknown\")\n",
        "          detected_type = r.get(\"type\", \"Unknown\")\n",
        "          # Extract key issues or summary points\n",
        "          notes = []\n",
        "          if status == \"FailedPreparation\":\n",
        "               notes.append(\"Pipeline failed or was not confirmed.\")\n",
        "          elif isinstance(r.get(\"data\"), dict): # Check if data exists for successful runs\n",
        "               data = r[\"data\"]\n",
        "               if detected_type == \"OTHER_HEURISTIC\":\n",
        "                    notes.append(\"Miscategorized by placeholder.\")\n",
        "               if data.get(\"travel_date_range\", \"\").startswith(\"SimulatedData_NotFound\"):\n",
        "                    notes.append(\"Optional info sim data missing.\")\n",
        "               if \"flight_cost_matrix\" not in data and detected_type == \"TSP_FLIGHTS\":\n",
        "                    notes.append(\"Flight matrix missing (API Error?).\")\n",
        "               if not data.get(\"item_list_dimensions_values\") and detected_type == \"KNAPSACK_MOVING\":\n",
        "                   notes.append(\"Knapsack items missing.\")\n",
        "               # Add more specific checks based on expected data for each type\n",
        "          elif status == \"DisplayError\":\n",
        "                notes.append(\"Error displaying final data.\")\n",
        "\n",
        "          if not notes:\n",
        "               notes.append(\"Completed successfully.\")\n",
        "\n",
        "          table_data.append([index, status, detected_type, \"; \".join(notes)])\n",
        "\n",
        "     # Use tabulate to create the Markdown table\n",
        "     try:\n",
        "        return tabulate(table_data, headers=headers, tablefmt=\"pipe\")\n",
        "     except ImportError:\n",
        "          print(\"\\nError: 'tabulate' library not found. Cannot generate table.\")\n",
        "          print(\"Install it using: pip install tabulate\")\n",
        "          # Fallback to simpler format if tabulate fails\n",
        "          table_str = \"| \" + \" | \".join(headers) + \" |\\n\"\n",
        "          table_str += \"| \" + \" | \".join([\"---\"] * len(headers)) + \" |\\n\"\n",
        "          for row in table_data:\n",
        "              table_str += \"| \" + \" | \".join(map(str, row)) + \" |\\n\"\n",
        "          return table_str\n",
        "     except Exception as e:\n",
        "         print(f\"\\nError generating table: {e}\")\n",
        "         return \"Table generation failed.\"\n",
        "\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n--- Starting Main Execution Block (run_simulation.py) ---\")\n",
        "\n",
        "    # --- Configuration ---\n",
        "    PROBLEMS_CSV_PATH = 'problems.csv'\n",
        "    SIMULATION_CSV_PATH = 'problem_info_reqs.csv'\n",
        "    GEMINI_API_KEY = None\n",
        "    FLIGHT_API_KEY = None\n",
        "\n",
        "    print(\"\\nConfiguration:\")\n",
        "    print(f\"  Problem Descriptions CSV: {PROBLEMS_CSV_PATH}\")\n",
        "    print(f\"  Simulation Requirements CSV: {SIMULATION_CSV_PATH}\")\n",
        "    print(f\"  Gemini API Key Provided: {bool(GEMINI_API_KEY)}\")\n",
        "    print(f\"  Flight API Key Provided: {bool(FLIGHT_API_KEY)}\")\n",
        "\n",
        "    # --- Create/Ensure Dummy Files Exist ---\n",
        "    print(\"\\nEnsuring Input Files Exist...\")\n",
        "    # Create problems.csv if needed - *USE THE FULL 10 DESCRIPTIONS HERE FOR FULL ANALYSIS*\n",
        "    if not os.path.exists(PROBLEMS_CSV_PATH):\n",
        "        print(f\"  Creating dummy problem description CSV: {PROBLEMS_CSV_PATH}\")\n",
        "        # **IMPORTANT**: For full analysis, replace this list with the 10 problem descriptions\n",
        "        dummy_problems_data = {'ProblemDescription': [\n",
        "            \"I need to visit all the following European cities in the most efficient order: London, Paris, Berlin, Rome, Madrid, Amsterdam, Prague, Vienna, Budapest, and Barcelona. I'll fly between them and want to minimize my total airfare and travel time.\", # Problem 1\n",
        "            \"I'm planning a road trip through the US national parks. I want to visit Yellowstone, Grand Canyon, Yosemite, Zion, Olympic, Glacier, Acadia, Great Smoky Mountains, Grand Teton, and Rocky Mountain. I need to find the most fuel-efficient route based on my car that gets 25 MPG.\", # Problem 2\n",
        "            \"I need to move items from my 3-bedroom apartment in Boston to my new place in Chicago. I have furniture pieces of different sizes and values, and I need to determine which items to take in a 26-foot U-Haul truck to maximize the value of what I bring.\", # Problem 3\n",
        "            \"Our delivery service needs to distribute packages to 45 addresses across Manhattan using 5 drivers. We need routes that account for real-time traffic conditions and ensure all deliveries happen within promised time windows.\", # Problem 4\n",
        "            \"I need to find the optimal locations for 7 new coffee shops in Seattle to maximize potential customers while ensuring shops are at least 0.5 miles apart and accounting for competitor locations.\", # Problem 5\n",
        "            \"I need to schedule 25 nurses across 3 shifts at Massachusetts General Hospital, considering their shift preferences, required skill levels for each ward, and ensuring no one works more than 5 consecutive days.\", # Problem 6\n",
        "            \"I need to invest $50,000 across stocks from the S&P 500, bonds, and ETFs to maximize returns with a risk level I'm comfortable with and proper diversification across sectors.\", # Problem 7\n",
        "            \"I'm organizing a conference at the Hilton Chicago with 35 sessions across 8 rooms over 3 days. I need to schedule them to minimize room changes for topic tracks and avoid scheduling similar topics simultaneously.\", # Problem 8\n",
        "            \"I need to plan the construction sequence for our 50-story building in downtown Miami, determining the optimal order of tasks considering crew availability, material delivery times, and weather forecasts to minimize the project timeline.\", # Problem 9\n",
        "            \"I need to design a water distribution network for a new development in Phoenix with 120 homes, determining pipe diameters and pump capacities to ensure adequate pressure while minimizing infrastructure costs.\" # Problem 10\n",
        "        ]}\n",
        "        try: pd.DataFrame(dummy_problems_data).to_csv(PROBLEMS_CSV_PATH, index=False); print(f\"  Successfully created {PROBLEMS_CSV_PATH} with 10 problems.\")\n",
        "        except Exception as e: print(f\"  Error creating dummy {PROBLEMS_CSV_PATH}: {e}\")\n",
        "    else: print(f\"  Using existing problem description CSV: {PROBLEMS_CSV_PATH}\")\n",
        "\n",
        "    # Ensure simulation requirements file exists\n",
        "    if not os.path.exists(SIMULATION_CSV_PATH):\n",
        "         print(f\"  ERROR: {SIMULATION_CSV_PATH} not found. Please create this file with the full requirements.\")\n",
        "         # Create basic dummy file (won't provide good simulation answers for all types)\n",
        "         print(f\"  Creating basic dummy requirements CSV: {SIMULATION_CSV_PATH}\")\n",
        "         dummy_reqs_data = {\n",
        "             'ProblemID': [1, 3, 3], 'ProblemType': [\"Traveling Salesman Problem\", \"Knapsack/Bin Packing Problem\", \"Knapsack/Bin Packing Problem\"],\n",
        "             'RequiredInfoDescription': [\"Airport Transfer Times per City\", \"List of items with dimensions (width, height, depth) and value\", \"Truck cargo dimensions (width, height, depth)\"],\n",
        "             'Format_Example': [\"1.5, 1.0, 1.2\", \"[{'name':'Painting', 'width_cm':50, 'height_cm':50, 'depth_cm':10, 'value_usd':10000}, {'name':'Sculpture', 'width_cm':30, 'height_cm':30, 'depth_cm':80, 'value_usd':5000}]\", \"100, 100, 100\"],\n",
        "             'AutomationNotes': [\"Estimate or User Input\", \"User Input File\", \"User Input\"]\n",
        "         }\n",
        "         try: pd.DataFrame(dummy_reqs_data).to_csv(SIMULATION_CSV_PATH, index=False); print(f\"  Successfully created basic dummy {SIMULATION_CSV_PATH}.\")\n",
        "         except Exception as e: print(f\"  Error creating dummy {SIMULATION_CSV_PATH}: {e}\")\n",
        "    else: print(f\"  Using existing simulation requirements CSV: {SIMULATION_CSV_PATH}\")\n",
        "\n",
        "\n",
        "    # --- Load Data ---\n",
        "    print(\"\\nLoading Data...\")\n",
        "    problems_df = read_problems_df_from_csv(PROBLEMS_CSV_PATH)\n",
        "    simulation_reqs_df = load_simulation_data(SIMULATION_CSV_PATH)\n",
        "\n",
        "    # --- Instantiate Solver Prep ---\n",
        "    print(\"\\nInstantiating SolvePrep...\")\n",
        "    prep = SolvePrep(gemini_api_key=GEMINI_API_KEY, flight_api_key=FLIGHT_API_KEY)\n",
        "    print(\"SolvePrep Instantiated.\")\n",
        "\n",
        "    # --- Process Each Problem ---\n",
        "    all_results_summary = [] # Store summary results for final table\n",
        "    if problems_df is not None and simulation_reqs_df is not None:\n",
        "        print(f\"\\n--- Starting to Process {len(problems_df)} Problems ---\")\n",
        "\n",
        "        for index, row in problems_df.iterrows():\n",
        "            problem_status = \"Unknown\"\n",
        "            problem_type_name = \"Unknown\"\n",
        "            final_data = None\n",
        "\n",
        "            if 'ProblemDescription' not in row:\n",
        "                print(f\"\\nSkipping row {index}: 'ProblemDescription' column missing.\")\n",
        "                all_results_summary.append({\"index\": index, \"status\": \"Skipped\", \"type\": \"N/A\", \"data\": None})\n",
        "                continue\n",
        "\n",
        "            problem_desc = row['ProblemDescription']\n",
        "            print(f\"\\n\\n<<<<<<<<<< Processing Problem Index {index} >>>>>>>>>>\")\n",
        "            print(f\"Description: '{problem_desc[:100]}...'\")\n",
        "\n",
        "            try:\n",
        "                prepared_context = prep.run_preparation_pipeline(problem_desc, simulation_data=simulation_reqs_df)\n",
        "\n",
        "                if prepared_context and prepared_context.is_confirmed:\n",
        "                    print(f\"\\n--- Problem {index} Preparation Complete ---\")\n",
        "                    problem_status = \"Success\"\n",
        "                    problem_type_name = prepared_context.identified_type.name\n",
        "                    final_data = prepared_context.extracted_data # Store for analysis table notes\n",
        "                    print(f\"  Type: {problem_type_name}\")\n",
        "                    print(\"  Final Prepared Data (JSON):\")\n",
        "                    try: print(json.dumps(final_data, indent=2, default=repr))\n",
        "                    except Exception as e: print(f\"  Error displaying final data as JSON: {e}\")\n",
        "                    print(\"\\n[Placeholder] Would proceed to EvoMoE stage for this problem now...\")\n",
        "                else:\n",
        "                    print(f\"\\n--- Problem {index} Preparation Failed or Not Confirmed ---\")\n",
        "                    problem_status = \"FailedPreparation\"\n",
        "                    # Try to get type if categorization happened before failure\n",
        "                    if prepared_context: problem_type_name = prepared_context.identified_type.name\n",
        "\n",
        "            except Exception as e:\n",
        "                 print(f\"\\n--- CRITICAL ERROR during processing Problem Index {index} ---\")\n",
        "                 print(f\"  Error: {e}\")\n",
        "                 problem_status = \"CriticalError\"\n",
        "                 # You might want to add more detailed error logging here\n",
        "\n",
        "            all_results_summary.append({\"index\": index, \"status\": problem_status, \"type\": problem_type_name, \"data\": final_data}) # Store result summary\n",
        "            print(f\"<<<<<<<<<< Finished Problem Index {index} >>>>>>>>>>\")\n",
        "\n",
        "        # --- Summary Table Generation ---\n",
        "        print(\"\\n\\n--- All Problems Processed ---\")\n",
        "        if all_results_summary:\n",
        "             print(\"\\n--- Final Analysis Table ---\")\n",
        "             # Pass the collected summary data to the table generator\n",
        "             analysis_table = generate_analysis_table(all_results_summary)\n",
        "             print(analysis_table)\n",
        "             print(\"--- End of Table ---\")\n",
        "        else:\n",
        "             print(\"No problems were processed or results collected.\")\n",
        "\n",
        "\n",
        "    elif simulation_reqs_df is None:\n",
        "         print(\"\\n--- Solver exiting: Could not load simulation requirements data. ---\")\n",
        "    else: # problems_df is None\n",
        "        print(\"\\n--- Solver exiting: Could not read problems from CSV. ---\")\n",
        "\n",
        "    print(\"\\n--- Main Execution Block Finished ---\")\n",
        "\n",
        "# --- End of run_simulation.py ---"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFr-4tRHukW-",
        "outputId": "4ce5e8f8-bdb9-43cb-a24e-8c3244e8f96a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error importing from solve_prep_utils.py: No module named 'solve_prep_utils'\n",
            "Ensure solve_prep_utils.py is in the same directory or Python path.\n",
            "\n",
            "--- Starting Main Execution Block (run_simulation.py) ---\n",
            "\n",
            "Configuration:\n",
            "  Problem Descriptions CSV: problems.csv\n",
            "  Simulation Requirements CSV: problem_info_reqs.csv\n",
            "  Gemini API Key Provided: False\n",
            "  Flight API Key Provided: False\n",
            "\n",
            "Ensuring Input Files Exist...\n",
            "  Using existing problem description CSV: problems.csv\n",
            "  Using existing simulation requirements CSV: problem_info_reqs.csv\n",
            "\n",
            "Loading Data...\n",
            "\n",
            "Reading all problems from 'problems.csv'...\n",
            "  Successfully read 10 problems.\n",
            "\n",
            "Loading simulation answers/requirements from 'problem_info_reqs.csv'...\n",
            "  Successfully loaded simulation data (54 rows).\n",
            "\n",
            "Instantiating SolvePrep...\n",
            "SolvePrep Instantiated.\n",
            "\n",
            "--- Starting to Process 10 Problems ---\n",
            "\n",
            "\n",
            "<<<<<<<<<< Processing Problem Index 0 >>>>>>>>>>\n",
            "Description: 'I need to visit all the following European cities in the most efficient order: London, Paris, Berlin...'\n",
            "\n",
            "Starting Preparation Pipeline...\n",
            "\n",
            "=== Step 1: Problem Categorization ===\n",
            "\n",
            "Step 1.1: Entering LLM Categorization...\n",
            "  Analyzing Full Input Description (Length: 244):\n",
            "  'I need to visit all the following European cities in the most efficient order: London, Paris, Berlin, Rome, Madrid, Amsterdam, Prague, Vienna, Budapest, and Barcelona. I'll fly between them and want to minimize my total airfare and travel time.'\n",
            "  [LLM Placeholder Rule Match] TSP_FLIGHTS keywords matched.\n",
            "  [LLM Placeholder] Final Categorization: TSP_FLIGHTS\n",
            "Step 1.1: Exiting LLM Categorization.\n",
            "Pipeline Update: Problem categorized as TSP_FLIGHTS\n",
            "\n",
            "=== Step 2: Initial Extraction / Automatic Data Fetching ===\n",
            "\n",
            "Step 2.1: Entering LLM Initial Data Extraction...\n",
            "  Problem Type: TSP_FLIGHTS\n",
            "  [LLM Placeholder] Extracted/Defaulted Cities: ['London', 'Paris', 'Berlin', 'Rome', 'Madrid', 'Amsterdam', 'Prague', 'Vienna', 'Budapest', 'Barcelona']\n",
            "  Output Extracted Data: {'list_of_cities': ['London', 'Paris', 'Berlin', 'Rome', 'Madrid', 'Amsterdam', 'Prague', 'Vienna', 'Budapest', 'Barcelona']}\n",
            "Step 2.1: Exiting LLM Initial Data Extraction.\n",
            "Pipeline Update: Initial data extracted: ['list_of_cities']\n",
            "\n",
            "--- Starting Automatic Flight Data Fetching ---\n",
            "\n",
            "Step 2.2.1: Entering Airport Code Lookup...\n",
            "  Input Cities: ['London', 'Paris', 'Berlin', 'Rome', 'Madrid', 'Amsterdam', 'Prague', 'Vienna', 'Budapest', 'Barcelona']\n",
            "  Searching for city: 'London'\n",
            "    Found code(s): ['YXU', 'LTN', 'BQH', 'LGW', 'LCY', 'LHR', 'STN', 'NHT', 'LOZ'] -> Selected: LHR\n",
            "  Searching for city: 'Paris'\n",
            "    Found code(s): ['PHT', 'PRX', 'LBG', 'CDG', 'ORY'] -> Selected: CDG\n",
            "  Searching for city: 'Berlin'\n",
            "    Found code(s): ['BER', 'TXL', 'BML'] -> Selected: BER\n",
            "  Searching for city: 'Rome'\n",
            "    Found code(s): ['REO', 'RME', 'RMG', 'FCO'] -> Selected: FCO\n",
            "  Searching for city: 'Madrid'\n",
            "    Found code(s): ['MAD', 'TOJ'] -> Selected: MAD\n",
            "  Searching for city: 'Amsterdam'\n",
            "    Found code(s): ['AMS'] -> Selected: AMS\n",
            "  Searching for city: 'Prague'\n",
            "    Found code(s): ['PRG'] -> Selected: PRG\n",
            "  Searching for city: 'Vienna'\n",
            "    Found code(s): ['VIE'] -> Selected: VIE\n",
            "  Searching for city: 'Budapest'\n",
            "    Found code(s): ['BUD'] -> Selected: BUD\n",
            "  Searching for city: 'Barcelona'\n",
            "    Found code(s): ['BCN', 'BLA'] -> Selected: BCN\n",
            "  Output City-to-Code Map: {'London': 'LHR', 'Paris': 'CDG', 'Berlin': 'BER', 'Rome': 'FCO', 'Madrid': 'MAD', 'Amsterdam': 'AMS', 'Prague': 'PRG', 'Vienna': 'VIE', 'Budapest': 'BUD', 'Barcelona': 'BCN'}\n",
            "Step 2.2.1: Exiting Airport Code Lookup.\n",
            "Pipeline Update: Stored city-to-code mapping.\n",
            "\n",
            "Step 2.2.2: Entering Flight Data Fetching (Placeholder)...\n",
            "  Attempting to fetch data for 10 cities with codes: ['LHR', 'CDG', 'BER', 'FCO', 'MAD', 'AMS', 'PRG', 'VIE', 'BUD', 'BCN']\n",
            "  Warning: Flight API key not provided.\n",
            "  Generating dummy flight data instead.\n",
            "    Generated dummy data for route London-Paris: Cost=935, Dur=2.5h\n",
            "    Generated dummy data for route London-Berlin: Cost=354, Dur=2.8h\n",
            "    Generated dummy data for route London-Rome: Cost=899, Dur=2.6h\n",
            "    Generated dummy data for route London-Madrid: Cost=475, Dur=8.3h\n",
            "    Generated dummy data for route London-Amsterdam: Cost=136, Dur=1.3h\n",
            "    Generated dummy data for route London-Prague: Cost=404, Dur=5.8h\n",
            "    Generated dummy data for route London-Vienna: Cost=132, Dur=7.3h\n",
            "    Generated dummy data for route London-Budapest: Cost=621, Dur=6.1h\n",
            "    Generated dummy data for route London-Barcelona: Cost=136, Dur=5.2h\n",
            "    Generated dummy data for route Paris-Berlin: Cost=425, Dur=7.4h\n",
            "    Generated dummy data for route Paris-Rome: Cost=987, Dur=3.1h\n",
            "    Generated dummy data for route Paris-Madrid: Cost=232, Dur=4.3h\n",
            "    Generated dummy data for route Paris-Amsterdam: Cost=461, Dur=4.7h\n",
            "    Generated dummy data for route Paris-Prague: Cost=380, Dur=2.0h\n",
            "    Generated dummy data for route Paris-Vienna: Cost=397, Dur=7.1h\n",
            "    Generated dummy data for route Paris-Budapest: Cost=144, Dur=1.8h\n",
            "    Generated dummy data for route Paris-Barcelona: Cost=827, Dur=5.7h\n",
            "    Generated dummy data for route Berlin-Rome: Cost=239, Dur=9.3h\n",
            "    Generated dummy data for route Berlin-Madrid: Cost=191, Dur=6.7h\n",
            "    Generated dummy data for route Berlin-Amsterdam: Cost=461, Dur=3.8h\n",
            "    Generated dummy data for route Berlin-Prague: Cost=901, Dur=3.7h\n",
            "    Generated dummy data for route Berlin-Vienna: Cost=787, Dur=4.5h\n",
            "    Generated dummy data for route Berlin-Budapest: Cost=848, Dur=1.6h\n",
            "    Generated dummy data for route Berlin-Barcelona: Cost=552, Dur=5.3h\n",
            "    Generated dummy data for route Rome-Madrid: Cost=930, Dur=1.5h\n",
            "    Generated dummy data for route Rome-Amsterdam: Cost=433, Dur=3.8h\n",
            "    Generated dummy data for route Rome-Prague: Cost=510, Dur=7.4h\n",
            "    Generated dummy data for route Rome-Vienna: Cost=423, Dur=9.6h\n",
            "    Generated dummy data for route Rome-Budapest: Cost=830, Dur=4.4h\n",
            "    Generated dummy data for route Rome-Barcelona: Cost=973, Dur=2.6h\n",
            "    Generated dummy data for route Madrid-Amsterdam: Cost=765, Dur=5.6h\n",
            "    Generated dummy data for route Madrid-Prague: Cost=372, Dur=9.9h\n",
            "    Generated dummy data for route Madrid-Vienna: Cost=618, Dur=10.0h\n",
            "    Generated dummy data for route Madrid-Budapest: Cost=391, Dur=3.8h\n",
            "    Generated dummy data for route Madrid-Barcelona: Cost=814, Dur=9.0h\n",
            "    Generated dummy data for route Amsterdam-Prague: Cost=793, Dur=4.6h\n",
            "    Generated dummy data for route Amsterdam-Vienna: Cost=481, Dur=1.9h\n",
            "    Generated dummy data for route Amsterdam-Budapest: Cost=929, Dur=9.9h\n",
            "    Generated dummy data for route Amsterdam-Barcelona: Cost=967, Dur=2.1h\n",
            "    Generated dummy data for route Prague-Vienna: Cost=170, Dur=8.3h\n",
            "    Generated dummy data for route Prague-Budapest: Cost=302, Dur=4.0h\n",
            "    Generated dummy data for route Prague-Barcelona: Cost=823, Dur=9.0h\n",
            "    Generated dummy data for route Vienna-Budapest: Cost=954, Dur=9.4h\n",
            "    Generated dummy data for route Vienna-Barcelona: Cost=102, Dur=1.8h\n",
            "    Generated dummy data for route Budapest-Barcelona: Cost=559, Dur=7.6h\n",
            "Step 2.2.2: Exiting Flight Data Fetching (Dummy Data).\n",
            "Pipeline Update: Successfully fetched/simulated flight data.\n",
            "--- End Automatic Flight Data Fetching ---\n",
            "\n",
            "=== Step 3 & 4: Manual Data Refinement / Simulation ===\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: TSP_FLIGHTS\n",
            "  Current Keys: ['list_of_cities', 'city_to_code', 'flight_cost_matrix', 'flight_duration_matrix']\n",
            "  Auto Keys: ['flight_cost_matrix', 'flight_duration_matrix']\n",
            "  [LLM Placeholder] Identified missing manual info: ['Airport Transfer Times per City', 'Preferred travel date range (optional)', 'Airline preferences (optional)'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: Manual data required for: ['Airport Transfer Times per City', 'Preferred travel date range (optional)', 'Airline preferences (optional)']\n",
            "\n",
            "--- Starting Simulation Loop ---\n",
            "--- Simulation Attempt 1 ---\n",
            "\n",
            "Step 4.2: Entering LLM Generate Questions...\n",
            "  Input Missing Info: ['Airport Transfer Times per City', 'Preferred travel date range (optional)', 'Airline preferences (optional)']\n",
            "  [LLM Placeholder] Generated questions: [\"Could you please provide the 'Airport Transfer Times per City'?\", \"Could you please provide the 'Preferred travel date range (optional)'?\", \"Could you please provide the 'Airline preferences (optional)'?\"] (using simple logic)\n",
            "Step 4.2: Exiting LLM Generate Questions.\n",
            "Pipeline Action: Simulating answers based on requirements CSV...\n",
            "    Found sim data for 'Airport Transfer Times per City': Using -> 'List of times (e.g., in hours) corresponding to the city list: 1.5, 1.0, 1.2,...'\n",
            "    Warning: No sim data found matching 'Preferred travel date range (optional)' for 'Traveling Salesman Problem'.\n",
            "    Warning: No sim data found matching 'Airline preferences (optional)' for 'Traveling Salesman Problem'.\n",
            "Pipeline Info: Simulated answers obtained: ['List of times (e.g., in hours) corresponding to the city list: 1.5, 1.0, 1.2,...', 'SimulatedData_NotFound_For_Preferred travel dat', 'SimulatedData_NotFound_For_Airline preferences ']\n",
            "\n",
            "Step 4.4: Entering Update Data Based on Answers...\n",
            "  Input Questions: [\"Could you please provide the 'Airport Transfer Times per City'?\", \"Could you please provide the 'Preferred travel date range (optional)'?\", \"Could you please provide the 'Airline preferences (optional)'?\"]\n",
            "  Input Answers: ['List of times (e.g., in hours) corresponding to the city list: 1.5, 1.0, 1.2,...', 'SimulatedData_NotFound_For_Preferred travel dat', 'SimulatedData_NotFound_For_Airline preferences ']\n",
            "    Updating/Adding key 'airport_transfer_times_hours' with value 'List of times (e.g., in hours) corresponding to the city list: 1.5, 1.0, 1.2,...'\n",
            "    Updating/Adding key 'travel_date_range' with value 'SimulatedData_NotFound_For_Preferred travel dat'\n",
            "    Updating/Adding key 'airline_preferences' with value 'SimulatedData_NotFound_For_Airline preferences '\n",
            "  Output Updated Data Keys: ['list_of_cities', 'city_to_code', 'flight_cost_matrix', 'flight_duration_matrix', 'airport_transfer_times_hours', 'travel_date_range', 'airline_preferences']\n",
            "Step 4.4: Exiting Update Data Based on Answers.\n",
            "Pipeline Update: Data updated with answers.\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: TSP_FLIGHTS\n",
            "  Current Keys: ['list_of_cities', 'city_to_code', 'flight_cost_matrix', 'flight_duration_matrix', 'airport_transfer_times_hours', 'travel_date_range', 'airline_preferences']\n",
            "  Auto Keys: ['flight_cost_matrix', 'flight_duration_matrix']\n",
            "  [LLM Placeholder] Identified missing manual info: [] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: All essential info seems gathered/simulated.\n",
            "--- End Simulation Loop ---\n",
            "\n",
            "=== Step 5: Post-Processing ===\n",
            "\n",
            "Step 5: Entering Geocoding (if needed)...\n",
            "  Attempting geocoding for locations in key: 'list_of_cities'\n",
            "    Geocoding 'London'...\n",
            "      Success: (51.4893335, -0.14405508452768728) (IATA: LHR)\n",
            "    Geocoding 'Paris'...\n",
            "      Success: (48.8534951, 2.3483915) (IATA: CDG)\n",
            "    Geocoding 'Berlin'...\n",
            "      Success: (52.510885, 13.3989367) (IATA: BER)\n",
            "    Geocoding 'Rome'...\n",
            "      Success: (41.8933203, 12.4829321) (IATA: FCO)\n",
            "    Geocoding 'Madrid'...\n",
            "      Success: (40.4167047, -3.7035825) (IATA: MAD)\n",
            "    Geocoding 'Amsterdam'...\n",
            "      Success: (52.3730796, 4.8924534) (IATA: AMS)\n",
            "    Geocoding 'Prague'...\n",
            "      Success: (50.0596288, 14.446459273258009) (IATA: PRG)\n",
            "    Geocoding 'Vienna'...\n",
            "      Success: (48.2083537, 16.3725042) (IATA: VIE)\n",
            "    Geocoding 'Budapest'...\n",
            "      Success: (47.48138955, 19.14609412691246) (IATA: BUD)\n",
            "    Geocoding 'Barcelona'...\n",
            "      Success: (41.3828939, 2.1774322) (IATA: BCN)\n",
            "  Geocoding complete.\n",
            "Step 5: Exiting Geocoding.\n",
            "\n",
            "=== Step 6: Final Confirmation ===\n",
            "\n",
            "Step 6: Entering Present Data for Confirmation...\n",
            "  Identified Problem Type: TSP_FLIGHTS\n",
            "  Collected & Prepared Data:\n",
            "{\n",
            "  \"list_of_cities\": [\n",
            "    \"London\",\n",
            "    \"Paris\",\n",
            "    \"Berlin\",\n",
            "    \"Rome\",\n",
            "    \"Madrid\",\n",
            "    \"Amsterdam\",\n",
            "    \"Prague\",\n",
            "    \"Vienna\",\n",
            "    \"Budapest\",\n",
            "    \"Barcelona\"\n",
            "  ],\n",
            "  \"city_to_code\": {\n",
            "    \"London\": \"LHR\",\n",
            "    \"Paris\": \"CDG\",\n",
            "    \"Berlin\": \"BER\",\n",
            "    \"Rome\": \"FCO\",\n",
            "    \"Madrid\": \"MAD\",\n",
            "    \"Amsterdam\": \"AMS\",\n",
            "    \"Prague\": \"PRG\",\n",
            "    \"Vienna\": \"VIE\",\n",
            "    \"Budapest\": \"BUD\",\n",
            "    \"Barcelona\": \"BCN\"\n",
            "  },\n",
            "  \"flight_cost_matrix\": \"array([[  0.        , 934.90195037, 353.63735328, 899.30566563,\\n        475.04721331, 135.90772351, 404.3400445 , 132.26842301,\\n        621.4456899 , 136.02486251],\\n       [934.90195037,   0.        , 425.17659211, 986.85734776,\\n        232.22207367, 461.08644429, 380.11322194, 396.53111298,\\n        144.16181342, 826.66670019],\\n       [353.63735328, 425.17659211,   0.        , 239.06788769,\\n        190.79441437, 461.26848231, 901.39516911, 786.6181241 ,\\n        847.88693337, 552.42762322],\\n       [899.30566563, 986.85734776, 239.06788769,   0.        ,\\n        929.70612344, 432.67818948, 510.44936533, 422.51552281,\\n        829.90330657, 973.39429339],\\n       [475.04721331, 232.22207367, 190.79441437, 929.70612344,\\n          0.        , 765.36709957, 371.99143191, 618.16948716,\\n        390.57246456, 813.75417804],\\n       [135.90772351, 461.08644429, 461.26848231, 432.67818948,\\n        765.36709957,   0.        , 792.83306472, 480.7392536 ,\\n        928.81038626, 966.9788137 ],\\n       [404.3400445 , 380.11322194, 901.39516911, 510.44936533,\\n        371.99143191, 792.83306472,   0.        , 170.03613861,\\n        301.89762927, 822.62499795],\\n       [132.26842301, 396.53111298, 786.6181241 , 422.51552281,\\n        618.16948716, 480.7392536 , 170.03613861,   0.        ,\\n        953.71823276, 101.95733809],\\n       [621.4456899 , 144.16181342, 847.88693337, 829.90330657,\\n        390.57246456, 928.81038626, 301.89762927, 953.71823276,\\n          0.        , 559.24911871],\\n       [136.02486251, 826.66670019, 552.42762322, 973.39429339,\\n        813.75417804, 966.9788137 , 822.62499795, 101.95733809,\\n        559.24911871,   0.        ]])\",\n",
            "  \"flight_duration_matrix\": \"array([[0.        , 2.45529598, 2.78971758, 2.61519688, 8.32294542,\\n        1.32745883, 5.75591806, 7.30297162, 6.13167109, 5.24685999],\\n       [2.45529598, 0.        , 7.42480834, 3.11235564, 4.34607864,\\n        4.67056249, 2.04848366, 7.12393351, 1.78924808, 5.68437197],\\n       [2.78971758, 7.42480834, 0.        , 9.31774758, 6.73185427,\\n        3.81290027, 3.74609146, 4.45184904, 1.61470087, 5.34624878],\\n       [2.61519688, 3.11235564, 9.31774758, 0.        , 1.47876003,\\n        3.75023083, 7.43526361, 9.60557965, 4.37961923, 2.6346216 ],\\n       [8.32294542, 4.34607864, 6.73185427, 1.47876003, 0.        ,\\n        5.59729315, 9.87577419, 9.98615723, 3.83744764, 8.95534468],\\n       [1.32745883, 4.67056249, 3.81290027, 3.75023083, 5.59729315,\\n        0.        , 4.59328935, 1.94526529, 9.88118479, 2.09527436],\\n       [5.75591806, 2.04848366, 3.74609146, 7.43526361, 9.87577419,\\n        4.59328935, 0.        , 8.34477037, 4.00389877, 9.00488183],\\n       [7.30297162, 7.12393351, 4.45184904, 9.60557965, 9.98615723,\\n        1.94526529, 8.34477037, 0.        , 9.38258519, 1.76113552],\\n       [6.13167109, 1.78924808, 1.61470087, 4.37961923, 3.83744764,\\n        9.88118479, 4.00389877, 9.38258519, 0.        , 7.56761879],\\n       [5.24685999, 5.68437197, 5.34624878, 2.6346216 , 8.95534468,\\n        2.09527436, 9.00488183, 1.76113552, 7.56761879, 0.        ]])\",\n",
            "  \"airport_transfer_times_hours\": \"List of times (e.g., in hours) corresponding to the city list: 1.5, 1.0, 1.2,...\",\n",
            "  \"travel_date_range\": \"SimulatedData_NotFound_For_Preferred travel dat\",\n",
            "  \"airline_preferences\": \"SimulatedData_NotFound_For_Airline preferences \",\n",
            "  \"geocoded_locations\": [\n",
            "    \"Location(name='London', address='London, Greater London, England, United Kingdom', coords=(51.4893335, -0.14405508452768728), iata_code='LHR')\",\n",
            "    \"Location(name='Paris', address='Paris, \\u00cele-de-France, France m\\u00e9tropolitaine, France', coords=(48.8534951, 2.3483915), iata_code='CDG')\",\n",
            "    \"Location(name='Berlin', address='Berlin, Deutschland', coords=(52.510885, 13.3989367), iata_code='BER')\",\n",
            "    \"Location(name='Rome', address='Roma, Roma Capitale, Lazio, Italia', coords=(41.8933203, 12.4829321), iata_code='FCO')\",\n",
            "    \"Location(name='Madrid', address='Madrid, Comunidad de Madrid, Espa\\u00f1a', coords=(40.4167047, -3.7035825), iata_code='MAD')\",\n",
            "    \"Location(name='Amsterdam', address='Amsterdam, Noord-Holland, Nederland', coords=(52.3730796, 4.8924534), iata_code='AMS')\",\n",
            "    \"Location(name='Prague', address='Praha, obvod Praha 4, Hlavn\\u00ed m\\u011bsto Praha, Praha, \\u010cesko', coords=(50.0596288, 14.446459273258009), iata_code='PRG')\",\n",
            "    \"Location(name='Vienna', address='Wien, \\u00d6sterreich', coords=(48.2083537, 16.3725042), iata_code='VIE')\",\n",
            "    \"Location(name='Budapest', address='Budapest, K\\u00f6z\\u00e9p-Magyarorsz\\u00e1g, Magyarorsz\\u00e1g', coords=(47.48138955, 19.14609412691246), iata_code='BUD')\",\n",
            "    \"Location(name='Barcelona', address='Barcelona, Barcelon\\u00e8s, Barcelona, Catalunya, Espa\\u00f1a', coords=(41.3828939, 2.1774322), iata_code='BCN')\"\n",
            "  ]\n",
            "}\n",
            "  > Is the above problem formulation correct...?: yes (Simulated)\n",
            "  User confirmation status: True\n",
            "Step 6: Exiting Present Data for Confirmation.\n",
            "\n",
            "Preparation Pipeline Completed Successfully.\n",
            "\n",
            "--- Problem 0 Preparation Complete ---\n",
            "  Type: TSP_FLIGHTS\n",
            "  Final Prepared Data (JSON):\n",
            "{\n",
            "  \"list_of_cities\": [\n",
            "    \"London\",\n",
            "    \"Paris\",\n",
            "    \"Berlin\",\n",
            "    \"Rome\",\n",
            "    \"Madrid\",\n",
            "    \"Amsterdam\",\n",
            "    \"Prague\",\n",
            "    \"Vienna\",\n",
            "    \"Budapest\",\n",
            "    \"Barcelona\"\n",
            "  ],\n",
            "  \"city_to_code\": {\n",
            "    \"London\": \"LHR\",\n",
            "    \"Paris\": \"CDG\",\n",
            "    \"Berlin\": \"BER\",\n",
            "    \"Rome\": \"FCO\",\n",
            "    \"Madrid\": \"MAD\",\n",
            "    \"Amsterdam\": \"AMS\",\n",
            "    \"Prague\": \"PRG\",\n",
            "    \"Vienna\": \"VIE\",\n",
            "    \"Budapest\": \"BUD\",\n",
            "    \"Barcelona\": \"BCN\"\n",
            "  },\n",
            "  \"flight_cost_matrix\": \"array([[  0.        , 934.90195037, 353.63735328, 899.30566563,\\n        475.04721331, 135.90772351, 404.3400445 , 132.26842301,\\n        621.4456899 , 136.02486251],\\n       [934.90195037,   0.        , 425.17659211, 986.85734776,\\n        232.22207367, 461.08644429, 380.11322194, 396.53111298,\\n        144.16181342, 826.66670019],\\n       [353.63735328, 425.17659211,   0.        , 239.06788769,\\n        190.79441437, 461.26848231, 901.39516911, 786.6181241 ,\\n        847.88693337, 552.42762322],\\n       [899.30566563, 986.85734776, 239.06788769,   0.        ,\\n        929.70612344, 432.67818948, 510.44936533, 422.51552281,\\n        829.90330657, 973.39429339],\\n       [475.04721331, 232.22207367, 190.79441437, 929.70612344,\\n          0.        , 765.36709957, 371.99143191, 618.16948716,\\n        390.57246456, 813.75417804],\\n       [135.90772351, 461.08644429, 461.26848231, 432.67818948,\\n        765.36709957,   0.        , 792.83306472, 480.7392536 ,\\n        928.81038626, 966.9788137 ],\\n       [404.3400445 , 380.11322194, 901.39516911, 510.44936533,\\n        371.99143191, 792.83306472,   0.        , 170.03613861,\\n        301.89762927, 822.62499795],\\n       [132.26842301, 396.53111298, 786.6181241 , 422.51552281,\\n        618.16948716, 480.7392536 , 170.03613861,   0.        ,\\n        953.71823276, 101.95733809],\\n       [621.4456899 , 144.16181342, 847.88693337, 829.90330657,\\n        390.57246456, 928.81038626, 301.89762927, 953.71823276,\\n          0.        , 559.24911871],\\n       [136.02486251, 826.66670019, 552.42762322, 973.39429339,\\n        813.75417804, 966.9788137 , 822.62499795, 101.95733809,\\n        559.24911871,   0.        ]])\",\n",
            "  \"flight_duration_matrix\": \"array([[0.        , 2.45529598, 2.78971758, 2.61519688, 8.32294542,\\n        1.32745883, 5.75591806, 7.30297162, 6.13167109, 5.24685999],\\n       [2.45529598, 0.        , 7.42480834, 3.11235564, 4.34607864,\\n        4.67056249, 2.04848366, 7.12393351, 1.78924808, 5.68437197],\\n       [2.78971758, 7.42480834, 0.        , 9.31774758, 6.73185427,\\n        3.81290027, 3.74609146, 4.45184904, 1.61470087, 5.34624878],\\n       [2.61519688, 3.11235564, 9.31774758, 0.        , 1.47876003,\\n        3.75023083, 7.43526361, 9.60557965, 4.37961923, 2.6346216 ],\\n       [8.32294542, 4.34607864, 6.73185427, 1.47876003, 0.        ,\\n        5.59729315, 9.87577419, 9.98615723, 3.83744764, 8.95534468],\\n       [1.32745883, 4.67056249, 3.81290027, 3.75023083, 5.59729315,\\n        0.        , 4.59328935, 1.94526529, 9.88118479, 2.09527436],\\n       [5.75591806, 2.04848366, 3.74609146, 7.43526361, 9.87577419,\\n        4.59328935, 0.        , 8.34477037, 4.00389877, 9.00488183],\\n       [7.30297162, 7.12393351, 4.45184904, 9.60557965, 9.98615723,\\n        1.94526529, 8.34477037, 0.        , 9.38258519, 1.76113552],\\n       [6.13167109, 1.78924808, 1.61470087, 4.37961923, 3.83744764,\\n        9.88118479, 4.00389877, 9.38258519, 0.        , 7.56761879],\\n       [5.24685999, 5.68437197, 5.34624878, 2.6346216 , 8.95534468,\\n        2.09527436, 9.00488183, 1.76113552, 7.56761879, 0.        ]])\",\n",
            "  \"airport_transfer_times_hours\": \"List of times (e.g., in hours) corresponding to the city list: 1.5, 1.0, 1.2,...\",\n",
            "  \"travel_date_range\": \"SimulatedData_NotFound_For_Preferred travel dat\",\n",
            "  \"airline_preferences\": \"SimulatedData_NotFound_For_Airline preferences \",\n",
            "  \"geocoded_locations\": [\n",
            "    \"Location(name='London', address='London, Greater London, England, United Kingdom', coords=(51.4893335, -0.14405508452768728), iata_code='LHR')\",\n",
            "    \"Location(name='Paris', address='Paris, \\u00cele-de-France, France m\\u00e9tropolitaine, France', coords=(48.8534951, 2.3483915), iata_code='CDG')\",\n",
            "    \"Location(name='Berlin', address='Berlin, Deutschland', coords=(52.510885, 13.3989367), iata_code='BER')\",\n",
            "    \"Location(name='Rome', address='Roma, Roma Capitale, Lazio, Italia', coords=(41.8933203, 12.4829321), iata_code='FCO')\",\n",
            "    \"Location(name='Madrid', address='Madrid, Comunidad de Madrid, Espa\\u00f1a', coords=(40.4167047, -3.7035825), iata_code='MAD')\",\n",
            "    \"Location(name='Amsterdam', address='Amsterdam, Noord-Holland, Nederland', coords=(52.3730796, 4.8924534), iata_code='AMS')\",\n",
            "    \"Location(name='Prague', address='Praha, obvod Praha 4, Hlavn\\u00ed m\\u011bsto Praha, Praha, \\u010cesko', coords=(50.0596288, 14.446459273258009), iata_code='PRG')\",\n",
            "    \"Location(name='Vienna', address='Wien, \\u00d6sterreich', coords=(48.2083537, 16.3725042), iata_code='VIE')\",\n",
            "    \"Location(name='Budapest', address='Budapest, K\\u00f6z\\u00e9p-Magyarorsz\\u00e1g, Magyarorsz\\u00e1g', coords=(47.48138955, 19.14609412691246), iata_code='BUD')\",\n",
            "    \"Location(name='Barcelona', address='Barcelona, Barcelon\\u00e8s, Barcelona, Catalunya, Espa\\u00f1a', coords=(41.3828939, 2.1774322), iata_code='BCN')\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "[Placeholder] Would proceed to EvoMoE stage for this problem now...\n",
            "<<<<<<<<<< Finished Problem Index 0 >>>>>>>>>>\n",
            "\n",
            "\n",
            "<<<<<<<<<< Processing Problem Index 1 >>>>>>>>>>\n",
            "Description: 'I'm planning a road trip through the US national parks. I want to visit Yellowstone, Grand Canyon, Y...'\n",
            "\n",
            "Starting Preparation Pipeline...\n",
            "\n",
            "=== Step 1: Problem Categorization ===\n",
            "\n",
            "Step 1.1: Entering LLM Categorization...\n",
            "  Analyzing Full Input Description (Length: 275):\n",
            "  'I'm planning a road trip through the US national parks. I want to visit Yellowstone, Grand Canyon, Yosemite, Zion, Olympic, Glacier, Acadia, Great Smoky Mountains, Grand Teton, and Rocky Mountain. I need to find the most fuel-efficient route based on my car that gets 25 MPG.'\n",
            "  [LLM Placeholder Rule Match] TSP_DRIVING_FUEL keywords matched.\n",
            "  [LLM Placeholder] Final Categorization: TSP_DRIVING_FUEL\n",
            "Step 1.1: Exiting LLM Categorization.\n",
            "Pipeline Update: Problem categorized as TSP_DRIVING_FUEL\n",
            "\n",
            "=== Step 2: Initial Extraction / Automatic Data Fetching ===\n",
            "\n",
            "Step 2.1: Entering LLM Initial Data Extraction...\n",
            "  Problem Type: TSP_DRIVING_FUEL\n",
            "  [LLM Placeholder] Extracted Parks/Locations: ['Yellowstone', 'Yosemite', 'Zion', 'Olympic', 'Glacier', 'Acadia', 'Teton']\n",
            "  [LLM Placeholder] Extracted MPG: 25.0\n",
            "  Output Extracted Data: {'list_of_locations': ['Yellowstone', 'Yosemite', 'Zion', 'Olympic', 'Glacier', 'Acadia', 'Teton'], 'vehicle_mpg': 25.0}\n",
            "Step 2.1: Exiting LLM Initial Data Extraction.\n",
            "Pipeline Update: Initial data extracted: ['list_of_locations', 'vehicle_mpg']\n",
            "Pipeline Info: No automatic data fetching configured for this problem type in Step 2.\n",
            "\n",
            "=== Step 3 & 4: Manual Data Refinement / Simulation ===\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: TSP_DRIVING_FUEL\n",
            "  Current Keys: ['list_of_locations', 'vehicle_mpg']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['Driving Distances between Park Entrances/Locations', 'Elevation Data along Routes', 'Seasonal Park Closures/Road Status'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: Manual data required for: ['Driving Distances between Park Entrances/Locations', 'Elevation Data along Routes', 'Seasonal Park Closures/Road Status']\n",
            "\n",
            "--- Starting Simulation Loop ---\n",
            "--- Simulation Attempt 1 ---\n",
            "\n",
            "Step 4.2: Entering LLM Generate Questions...\n",
            "  Input Missing Info: ['Driving Distances between Park Entrances/Locations', 'Elevation Data along Routes', 'Seasonal Park Closures/Road Status']\n",
            "  [LLM Placeholder] Generated questions: [\"Could you please provide the 'Driving Distances between Park Entrances/Locations'?\", \"Could you please provide the 'Elevation Data along Routes'?\", \"Could you please provide the 'Seasonal Park Closures/Road Status'?\"] (using simple logic)\n",
            "Step 4.2: Exiting LLM Generate Questions.\n",
            "Pipeline Action: Simulating answers based on requirements CSV...\n",
            "    Found sim data for 'Driving Distances between Park Entrances/Locations': Using -> 'Distance Matrix (CSV/JSON, e.g., in miles)'\n",
            "    Found sim data for 'Elevation Data along Routes': Using -> 'API endpoint or dataset providing elevation changes for route segments'\n",
            "    Found sim data for 'Seasonal Park Closures/Road Status': Using -> 'List of parks with closure dates/status or API endpoint'\n",
            "Pipeline Info: Simulated answers obtained: ['Distance Matrix (CSV/JSON, e.g., in miles)', 'API endpoint or dataset providing elevation changes for route segments', 'List of parks with closure dates/status or API endpoint']\n",
            "\n",
            "Step 4.4: Entering Update Data Based on Answers...\n",
            "  Input Questions: [\"Could you please provide the 'Driving Distances between Park Entrances/Locations'?\", \"Could you please provide the 'Elevation Data along Routes'?\", \"Could you please provide the 'Seasonal Park Closures/Road Status'?\"]\n",
            "  Input Answers: ['Distance Matrix (CSV/JSON, e.g., in miles)', 'API endpoint or dataset providing elevation changes for route segments', 'List of parks with closure dates/status or API endpoint']\n",
            "    Updating/Adding key 'driving_distance_matrix_miles' with value 'Distance Matrix (CSV/JSON, e.g., in miles)'\n",
            "      (Storing potential file path/source as string)\n",
            "    Updating/Adding key 'route_elevation_data_source' with value 'API endpoint or dataset providing elevation changes for route segments'\n",
            "      (Storing potential file path/source as string)\n",
            "    Updating/Adding key 'park_closure_info_source' with value 'List of parks with closure dates/status or API endpoint'\n",
            "      (Storing potential file path/source as string)\n",
            "  Output Updated Data Keys: ['list_of_locations', 'vehicle_mpg', 'driving_distance_matrix_miles', 'route_elevation_data_source', 'park_closure_info_source']\n",
            "Step 4.4: Exiting Update Data Based on Answers.\n",
            "Pipeline Update: Data updated with answers.\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: TSP_DRIVING_FUEL\n",
            "  Current Keys: ['list_of_locations', 'vehicle_mpg', 'driving_distance_matrix_miles', 'route_elevation_data_source', 'park_closure_info_source']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: [] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: All essential info seems gathered/simulated.\n",
            "--- End Simulation Loop ---\n",
            "\n",
            "=== Step 5: Post-Processing ===\n",
            "\n",
            "Step 5: Entering Geocoding (if needed)...\n",
            "  Attempting geocoding for locations in key: 'list_of_locations'\n",
            "    Geocoding 'Yellowstone'...\n",
            "      Success: (45.9645464, -108.276076)\n",
            "    Geocoding 'Yosemite'...\n",
            "      Success: (-33.700872, 150.3161438)\n",
            "    Geocoding 'Zion'...\n",
            "      Success: (42.4501169, -87.8337753)\n",
            "    Geocoding 'Olympic'...\n",
            "      Success: (22.317798, 114.16023401336528)\n",
            "    Geocoding 'Glacier'...\n",
            "      Success: (48.6966449, -112.9467116)\n",
            "    Geocoding 'Acadia'...\n",
            "      Success: (30.2740735, -92.3957036)\n",
            "    Geocoding 'Teton'...\n",
            "      Success: (43.9139214, -110.6380363)\n",
            "  Geocoding complete.\n",
            "Step 5: Exiting Geocoding.\n",
            "\n",
            "=== Step 6: Final Confirmation ===\n",
            "\n",
            "Step 6: Entering Present Data for Confirmation...\n",
            "  Identified Problem Type: TSP_DRIVING_FUEL\n",
            "  Collected & Prepared Data:\n",
            "{\n",
            "  \"list_of_locations\": [\n",
            "    \"Yellowstone\",\n",
            "    \"Yosemite\",\n",
            "    \"Zion\",\n",
            "    \"Olympic\",\n",
            "    \"Glacier\",\n",
            "    \"Acadia\",\n",
            "    \"Teton\"\n",
            "  ],\n",
            "  \"vehicle_mpg\": 25.0,\n",
            "  \"driving_distance_matrix_miles\": \"Distance Matrix (CSV/JSON, e.g., in miles)\",\n",
            "  \"route_elevation_data_source\": \"API endpoint or dataset providing elevation changes for route segments\",\n",
            "  \"park_closure_info_source\": \"List of parks with closure dates/status or API endpoint\",\n",
            "  \"geocoded_locations\": [\n",
            "    \"Location(name='Yellowstone', address='Yellowstone County, Montana, United States', coords=(45.9645464, -108.276076), iata_code=None)\",\n",
            "    \"Location(name='Yosemite', address='Yosemite, Katoomba, Sydney, Blue Mountains City Council, New South Wales, 2780, Australia', coords=(-33.700872, 150.3161438), iata_code=None)\",\n",
            "    \"Location(name='Zion', address='Zion, Lake County, Illinois, 60099, United States', coords=(42.4501169, -87.8337753), iata_code=None)\",\n",
            "    \"Location(name='Olympic', address='\\u5967\\u904b Olympic, \\u6afb\\u6843\\u8857 Cherry Street, \\u5927\\u89d2\\u5480 Tai Kok Tsui, \\u6cb9\\u5c16\\u65fa\\u5340 Yau Tsim Mong District, \\u4e5d\\u9f8d Kowloon, \\u9999\\u6e2f Hong Kong, 999077, \\u4e2d\\u56fd', coords=(22.317798, 114.16023401336528), iata_code=None)\",\n",
            "    \"Location(name='Glacier', address='Glacier County, Montana, United States', coords=(48.6966449, -112.9467116), iata_code=None)\",\n",
            "    \"Location(name='Acadia', address='Acadia Parish, Louisiana, United States', coords=(30.2740735, -92.3957036), iata_code=None)\",\n",
            "    \"Location(name='Teton', address='Teton County, Wyoming, United States', coords=(43.9139214, -110.6380363), iata_code=None)\"\n",
            "  ]\n",
            "}\n",
            "  > Is the above problem formulation correct...?: yes (Simulated)\n",
            "  User confirmation status: True\n",
            "Step 6: Exiting Present Data for Confirmation.\n",
            "\n",
            "Preparation Pipeline Completed Successfully.\n",
            "\n",
            "--- Problem 1 Preparation Complete ---\n",
            "  Type: TSP_DRIVING_FUEL\n",
            "  Final Prepared Data (JSON):\n",
            "{\n",
            "  \"list_of_locations\": [\n",
            "    \"Yellowstone\",\n",
            "    \"Yosemite\",\n",
            "    \"Zion\",\n",
            "    \"Olympic\",\n",
            "    \"Glacier\",\n",
            "    \"Acadia\",\n",
            "    \"Teton\"\n",
            "  ],\n",
            "  \"vehicle_mpg\": 25.0,\n",
            "  \"driving_distance_matrix_miles\": \"Distance Matrix (CSV/JSON, e.g., in miles)\",\n",
            "  \"route_elevation_data_source\": \"API endpoint or dataset providing elevation changes for route segments\",\n",
            "  \"park_closure_info_source\": \"List of parks with closure dates/status or API endpoint\",\n",
            "  \"geocoded_locations\": [\n",
            "    \"Location(name='Yellowstone', address='Yellowstone County, Montana, United States', coords=(45.9645464, -108.276076), iata_code=None)\",\n",
            "    \"Location(name='Yosemite', address='Yosemite, Katoomba, Sydney, Blue Mountains City Council, New South Wales, 2780, Australia', coords=(-33.700872, 150.3161438), iata_code=None)\",\n",
            "    \"Location(name='Zion', address='Zion, Lake County, Illinois, 60099, United States', coords=(42.4501169, -87.8337753), iata_code=None)\",\n",
            "    \"Location(name='Olympic', address='\\u5967\\u904b Olympic, \\u6afb\\u6843\\u8857 Cherry Street, \\u5927\\u89d2\\u5480 Tai Kok Tsui, \\u6cb9\\u5c16\\u65fa\\u5340 Yau Tsim Mong District, \\u4e5d\\u9f8d Kowloon, \\u9999\\u6e2f Hong Kong, 999077, \\u4e2d\\u56fd', coords=(22.317798, 114.16023401336528), iata_code=None)\",\n",
            "    \"Location(name='Glacier', address='Glacier County, Montana, United States', coords=(48.6966449, -112.9467116), iata_code=None)\",\n",
            "    \"Location(name='Acadia', address='Acadia Parish, Louisiana, United States', coords=(30.2740735, -92.3957036), iata_code=None)\",\n",
            "    \"Location(name='Teton', address='Teton County, Wyoming, United States', coords=(43.9139214, -110.6380363), iata_code=None)\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "[Placeholder] Would proceed to EvoMoE stage for this problem now...\n",
            "<<<<<<<<<< Finished Problem Index 1 >>>>>>>>>>\n",
            "\n",
            "\n",
            "<<<<<<<<<< Processing Problem Index 2 >>>>>>>>>>\n",
            "Description: 'I need to move items from my 3-bedroom apartment in Boston to my new place in Chicago. I have furnit...'\n",
            "\n",
            "Starting Preparation Pipeline...\n",
            "\n",
            "=== Step 1: Problem Categorization ===\n",
            "\n",
            "Step 1.1: Entering LLM Categorization...\n",
            "  Analyzing Full Input Description (Length: 250):\n",
            "  'I need to move items from my 3-bedroom apartment in Boston to my new place in Chicago. I have furniture pieces of different sizes and values, and I need to determine which items to take in a 26-foot U-Haul truck to maximize the value of what I bring.'\n",
            "  [LLM Placeholder Rule Match] KNAPSACK_MOVING keywords matched.\n",
            "  [LLM Placeholder] Final Categorization: KNAPSACK_MOVING\n",
            "Step 1.1: Exiting LLM Categorization.\n",
            "Pipeline Update: Problem categorized as KNAPSACK_MOVING\n",
            "\n",
            "=== Step 2: Initial Extraction / Automatic Data Fetching ===\n",
            "\n",
            "Step 2.1: Entering LLM Initial Data Extraction...\n",
            "  Problem Type: KNAPSACK_MOVING\n",
            "  [LLM Placeholder] Extracted Truck Info: 26-foot U-Haul\n",
            "  Output Extracted Data: {'truck_info': '26-foot U-Haul'}\n",
            "Step 2.1: Exiting LLM Initial Data Extraction.\n",
            "Pipeline Update: Initial data extracted: ['truck_info']\n",
            "Pipeline Info: No automatic data fetching configured for this problem type in Step 2.\n",
            "\n",
            "=== Step 3 & 4: Manual Data Refinement / Simulation ===\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: KNAPSACK_MOVING\n",
            "  Current Keys: ['truck_info']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['List of items with dimensions (width, height, depth) and value', 'Truck cargo dimensions (width, height, depth)'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: Manual data required for: ['List of items with dimensions (width, height, depth) and value', 'Truck cargo dimensions (width, height, depth)']\n",
            "\n",
            "--- Starting Simulation Loop ---\n",
            "--- Simulation Attempt 1 ---\n",
            "\n",
            "Step 4.2: Entering LLM Generate Questions...\n",
            "  Input Missing Info: ['List of items with dimensions (width, height, depth) and value', 'Truck cargo dimensions (width, height, depth)']\n",
            "  [LLM Placeholder] Generated questions: [\"Could you please provide the 'List of items with dimensions (width, height, depth) and value'?\", \"Could you please provide the 'Truck cargo dimensions (width, height, depth)'?\"] (using simple logic)\n",
            "Step 4.2: Exiting LLM Generate Questions.\n",
            "Pipeline Action: Simulating answers based on requirements CSV...\n",
            "    Warning: No sim data found matching 'List of items with dimensions (width, height, depth) and value' for 'Knapsack/Bin Packing Problem'.\n",
            "    Warning: No sim data found matching 'Truck cargo dimensions (width, height, depth)' for 'Knapsack/Bin Packing Problem'.\n",
            "Pipeline Info: Simulated answers obtained: ['SimulatedData_NotFound_For_List of items with d', 'SimulatedData_NotFound_For_Truck cargo dimensio']\n",
            "\n",
            "Step 4.4: Entering Update Data Based on Answers...\n",
            "  Input Questions: [\"Could you please provide the 'List of items with dimensions (width, height, depth) and value'?\", \"Could you please provide the 'Truck cargo dimensions (width, height, depth)'?\"]\n",
            "  Input Answers: ['SimulatedData_NotFound_For_List of items with d', 'SimulatedData_NotFound_For_Truck cargo dimensio']\n",
            "    Updating/Adding key 'item_list_dimensions_values' with value 'SimulatedData_NotFound_For_List of items with d'\n",
            "    Updating/Adding key 'truck_dimensions' with value 'SimulatedData_NotFound_For_Truck cargo dimensio'\n",
            "  Output Updated Data Keys: ['truck_info', 'item_list_dimensions_values', 'truck_dimensions']\n",
            "Step 4.4: Exiting Update Data Based on Answers.\n",
            "Pipeline Update: Data updated with answers.\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: KNAPSACK_MOVING\n",
            "  Current Keys: ['truck_info', 'item_list_dimensions_values', 'truck_dimensions']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: [] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: All essential info seems gathered/simulated.\n",
            "--- End Simulation Loop ---\n",
            "\n",
            "=== Step 5: Post-Processing ===\n",
            "\n",
            "Step 5: Entering Geocoding (if needed)...\n",
            "  No suitable location list/string found for geocoding or data type incorrect.\n",
            "Step 5: Exiting Geocoding.\n",
            "\n",
            "=== Step 6: Final Confirmation ===\n",
            "\n",
            "Step 6: Entering Present Data for Confirmation...\n",
            "  Identified Problem Type: KNAPSACK_MOVING\n",
            "  Collected & Prepared Data:\n",
            "{\n",
            "  \"truck_info\": \"26-foot U-Haul\",\n",
            "  \"item_list_dimensions_values\": \"SimulatedData_NotFound_For_List of items with d\",\n",
            "  \"truck_dimensions\": \"SimulatedData_NotFound_For_Truck cargo dimensio\"\n",
            "}\n",
            "  > Is the above problem formulation correct...?: yes (Simulated)\n",
            "  User confirmation status: True\n",
            "Step 6: Exiting Present Data for Confirmation.\n",
            "\n",
            "Preparation Pipeline Completed Successfully.\n",
            "\n",
            "--- Problem 2 Preparation Complete ---\n",
            "  Type: KNAPSACK_MOVING\n",
            "  Final Prepared Data (JSON):\n",
            "{\n",
            "  \"truck_info\": \"26-foot U-Haul\",\n",
            "  \"item_list_dimensions_values\": \"SimulatedData_NotFound_For_List of items with d\",\n",
            "  \"truck_dimensions\": \"SimulatedData_NotFound_For_Truck cargo dimensio\"\n",
            "}\n",
            "\n",
            "[Placeholder] Would proceed to EvoMoE stage for this problem now...\n",
            "<<<<<<<<<< Finished Problem Index 2 >>>>>>>>>>\n",
            "\n",
            "\n",
            "<<<<<<<<<< Processing Problem Index 3 >>>>>>>>>>\n",
            "Description: 'Our delivery service needs to distribute packages to 45 addresses across Manhattan using 5 drivers. ...'\n",
            "\n",
            "Starting Preparation Pipeline...\n",
            "\n",
            "=== Step 1: Problem Categorization ===\n",
            "\n",
            "Step 1.1: Entering LLM Categorization...\n",
            "  Analyzing Full Input Description (Length: 223):\n",
            "  'Our delivery service needs to distribute packages to 45 addresses across Manhattan using 5 drivers. We need routes that account for real-time traffic conditions and ensure all deliveries happen within promised time windows.'\n",
            "  [LLM Placeholder Rule Match] VRP_MANHATTAN keywords matched.\n",
            "  [LLM Placeholder] Final Categorization: VRP_MANHATTAN\n",
            "Step 1.1: Exiting LLM Categorization.\n",
            "Pipeline Update: Problem categorized as VRP_MANHATTAN\n",
            "\n",
            "=== Step 2: Initial Extraction / Automatic Data Fetching ===\n",
            "\n",
            "Step 2.1: Entering LLM Initial Data Extraction...\n",
            "  Problem Type: VRP_MANHATTAN\n",
            "  [LLM Placeholder] Extracted Drivers: 5\n",
            "  [LLM Placeholder] Expected Addresses: 45\n",
            "  Output Extracted Data: {'num_drivers': 5, 'num_addresses_expected': 45}\n",
            "Step 2.1: Exiting LLM Initial Data Extraction.\n",
            "Pipeline Update: Initial data extracted: ['num_drivers', 'num_addresses_expected']\n",
            "\n",
            "--- Deferring Geocoding until after potential address list update ---\n",
            "\n",
            "=== Step 3 & 4: Manual Data Refinement / Simulation ===\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: VRP_MANHATTAN\n",
            "  Current Keys: ['num_drivers', 'num_addresses_expected']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['List of Delivery Addresses', 'Customer Delivery Time Windows', 'Real-time Traffic Data Source'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: Manual data required for: ['List of Delivery Addresses', 'Customer Delivery Time Windows', 'Real-time Traffic Data Source']\n",
            "\n",
            "--- Starting Simulation Loop ---\n",
            "--- Simulation Attempt 1 ---\n",
            "\n",
            "Step 4.2: Entering LLM Generate Questions...\n",
            "  Input Missing Info: ['List of Delivery Addresses', 'Customer Delivery Time Windows', 'Real-time Traffic Data Source']\n",
            "  [LLM Placeholder] Generated questions: [\"Could you please provide the 'List of Delivery Addresses'?\", \"Could you please provide the 'Customer Delivery Time Windows'?\", \"Could you please provide the 'Real-time Traffic Data Source'?\"] (using simple logic)\n",
            "Step 4.2: Exiting LLM Generate Questions.\n",
            "Pipeline Action: Simulating answers based on requirements CSV...\n",
            "    Found sim data for 'List of Delivery Addresses': Using -> 'List of full street addresses: ['123 Main St, New York, NY 10001', ...]'\n",
            "    Found sim data for 'Customer Delivery Time Windows': Using -> 'List per address: [{'address_idx': 0, 'start_time': '09:00', 'end_time': '11:00'}, ...]'\n",
            "    Found sim data for 'Real-time Traffic Data Source': Using -> 'API endpoint/key for traffic conditions'\n",
            "Pipeline Info: Simulated answers obtained: [\"List of full street addresses: ['123 Main St, New York, NY 10001', ...]\", \"List per address: [{'address_idx': 0, 'start_time': '09:00', 'end_time': '11:00'}, ...]\", 'API endpoint/key for traffic conditions']\n",
            "\n",
            "Step 4.4: Entering Update Data Based on Answers...\n",
            "  Input Questions: [\"Could you please provide the 'List of Delivery Addresses'?\", \"Could you please provide the 'Customer Delivery Time Windows'?\", \"Could you please provide the 'Real-time Traffic Data Source'?\"]\n",
            "  Input Answers: [\"List of full street addresses: ['123 Main St, New York, NY 10001', ...]\", \"List per address: [{'address_idx': 0, 'start_time': '09:00', 'end_time': '11:00'}, ...]\", 'API endpoint/key for traffic conditions']\n",
            "    Updating/Adding key 'delivery_addresses_list' with value 'List of full street addresses: ['123 Main St, New York, NY 10001', ...]'\n",
            "      (Could not parse answer as JSON list/dict, storing as string)\n",
            "    Updating/Adding key 'customer_delivery_time_windows' with value 'List per address: [{'address_idx': 0, 'start_time': '09:00', 'end_time': '11:00'}, ...]'\n",
            "    Updating/Adding key 'real_time_traffic_data_source' with value 'API endpoint/key for traffic conditions'\n",
            "      (Storing potential file path/source as string)\n",
            "  Output Updated Data Keys: ['num_drivers', 'num_addresses_expected', 'delivery_addresses_list', 'customer_delivery_time_windows', 'real_time_traffic_data_source']\n",
            "Step 4.4: Exiting Update Data Based on Answers.\n",
            "Pipeline Update: Data updated with answers.\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: VRP_MANHATTAN\n",
            "  Current Keys: ['num_drivers', 'num_addresses_expected', 'delivery_addresses_list', 'customer_delivery_time_windows', 'real_time_traffic_data_source']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: [] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: All essential info seems gathered/simulated.\n",
            "--- End Simulation Loop ---\n",
            "\n",
            "=== Step 5: Post-Processing ===\n",
            "\n",
            "Step 5: Entering Geocoding (if needed)...\n",
            "    Geocoding single location 'List of full street addresses: ['123 Main St, New York, NY 10001', ...]'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-666d4dbbd980>:505: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  matched_rows = simulation_data[(simulation_data['ProblemType'].str.lower() == problem_type_str_for_sim.lower()) & (simulation_data['RequiredInfoDescription'].str.lower().str.contains(search_term, na=False))]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Failed: Could not geocode.\n",
            "Step 5: Exiting Geocoding.\n",
            "\n",
            "=== Step 6: Final Confirmation ===\n",
            "\n",
            "Step 6: Entering Present Data for Confirmation...\n",
            "  Identified Problem Type: VRP_MANHATTAN\n",
            "  Collected & Prepared Data:\n",
            "{\n",
            "  \"num_drivers\": 5,\n",
            "  \"num_addresses_expected\": 45,\n",
            "  \"delivery_addresses_list\": \"List of full street addresses: ['123 Main St, New York, NY 10001', ...]\",\n",
            "  \"customer_delivery_time_windows\": \"List per address: [{'address_idx': 0, 'start_time': '09:00', 'end_time': '11:00'}, ...]\",\n",
            "  \"real_time_traffic_data_source\": \"API endpoint/key for traffic conditions\"\n",
            "}\n",
            "  > Is the above problem formulation correct...?: yes (Simulated)\n",
            "  User confirmation status: True\n",
            "Step 6: Exiting Present Data for Confirmation.\n",
            "\n",
            "Preparation Pipeline Completed Successfully.\n",
            "\n",
            "--- Problem 3 Preparation Complete ---\n",
            "  Type: VRP_MANHATTAN\n",
            "  Final Prepared Data (JSON):\n",
            "{\n",
            "  \"num_drivers\": 5,\n",
            "  \"num_addresses_expected\": 45,\n",
            "  \"delivery_addresses_list\": \"List of full street addresses: ['123 Main St, New York, NY 10001', ...]\",\n",
            "  \"customer_delivery_time_windows\": \"List per address: [{'address_idx': 0, 'start_time': '09:00', 'end_time': '11:00'}, ...]\",\n",
            "  \"real_time_traffic_data_source\": \"API endpoint/key for traffic conditions\"\n",
            "}\n",
            "\n",
            "[Placeholder] Would proceed to EvoMoE stage for this problem now...\n",
            "<<<<<<<<<< Finished Problem Index 3 >>>>>>>>>>\n",
            "\n",
            "\n",
            "<<<<<<<<<< Processing Problem Index 4 >>>>>>>>>>\n",
            "Description: 'I need to find the optimal locations for 7 new coffee shops in Seattle to maximize potential custome...'\n",
            "\n",
            "Starting Preparation Pipeline...\n",
            "\n",
            "=== Step 1: Problem Categorization ===\n",
            "\n",
            "Step 1.1: Entering LLM Categorization...\n",
            "  Analyzing Full Input Description (Length: 193):\n",
            "  'I need to find the optimal locations for 7 new coffee shops in Seattle to maximize potential customers while ensuring shops are at least 0.5 miles apart and accounting for competitor locations.'\n",
            "  [LLM Placeholder Rule Match] FACILITY_LOCATION_SEATTLE keywords matched.\n",
            "  [LLM Placeholder] Final Categorization: FACILITY_LOCATION_SEATTLE\n",
            "Step 1.1: Exiting LLM Categorization.\n",
            "Pipeline Update: Problem categorized as FACILITY_LOCATION_SEATTLE\n",
            "\n",
            "=== Step 2: Initial Extraction / Automatic Data Fetching ===\n",
            "\n",
            "Step 2.1: Entering LLM Initial Data Extraction...\n",
            "  Problem Type: FACILITY_LOCATION_SEATTLE\n",
            "  [LLM Placeholder] Extracted Num Shops: 7\n",
            "  [LLM Placeholder] Extracted Min Distance (miles): 0.5\n",
            "  Output Extracted Data: {'num_new_shops': 7, 'min_distance_miles': 0.5}\n",
            "Step 2.1: Exiting LLM Initial Data Extraction.\n",
            "Pipeline Update: Initial data extracted: ['num_new_shops', 'min_distance_miles']\n",
            "Pipeline Info: No automatic data fetching configured for this problem type in Step 2.\n",
            "\n",
            "=== Step 3 & 4: Manual Data Refinement / Simulation ===\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: FACILITY_LOCATION_SEATTLE\n",
            "  Current Keys: ['num_new_shops', 'min_distance_miles']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['Population Density Data', 'Competitor Locations', 'Commercial Real Estate Cost Data', 'Traffic Pattern Data', 'Target Geographic Area Definition (e.g., Seattle boundary)'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: Manual data required for: ['Population Density Data', 'Competitor Locations', 'Commercial Real Estate Cost Data', 'Traffic Pattern Data', 'Target Geographic Area Definition (e.g., Seattle boundary)']\n",
            "\n",
            "--- Starting Simulation Loop ---\n",
            "--- Simulation Attempt 1 ---\n",
            "\n",
            "Step 4.2: Entering LLM Generate Questions...\n",
            "  Input Missing Info: ['Population Density Data', 'Competitor Locations', 'Commercial Real Estate Cost Data', 'Traffic Pattern Data', 'Target Geographic Area Definition (e.g., Seattle boundary)']\n",
            "  [LLM Placeholder] Generated questions: [\"Could you please provide the 'Population Density Data'?\", \"Could you please provide the 'Competitor Locations'?\", \"Could you please provide the 'Commercial Real Estate Cost Data'?\", \"Could you please provide the 'Traffic Pattern Data'?\", \"Could you please provide the 'Target Geographic Area Definition (e.g., Seattle boundary)'?\"] (using simple logic)\n",
            "Step 4.2: Exiting LLM Generate Questions.\n",
            "Pipeline Action: Simulating answers based on requirements CSV...\n",
            "    Found sim data for 'Population Density Data': Using -> 'Dataset (e.g., GeoJSON, CSV grid) or API endpoint for the target area'\n",
            "    Found sim data for 'Competitor Locations': Using -> 'List of competitor addresses or geocoordinates'\n",
            "    Found sim data for 'Commercial Real Estate Cost Data': Using -> 'Dataset (e.g., price per sqft by zone) or API endpoint for the target area'\n",
            "    Found sim data for 'Traffic Pattern Data': Using -> 'Dataset (e.g., road network congestion) or API endpoint for the target area'\n",
            "    Warning: No sim data found matching 'Target Geographic Area Definition (e.g., Seattle boundary)' for 'Facility Location Problem'.\n",
            "Pipeline Info: Simulated answers obtained: ['Dataset (e.g., GeoJSON, CSV grid) or API endpoint for the target area', 'List of competitor addresses or geocoordinates', 'Dataset (e.g., price per sqft by zone) or API endpoint for the target area', 'Dataset (e.g., road network congestion) or API endpoint for the target area', 'SimulatedData_NotFound_For_Target Geographic Ar']\n",
            "\n",
            "Step 4.4: Entering Update Data Based on Answers...\n",
            "  Input Questions: [\"Could you please provide the 'Population Density Data'?\", \"Could you please provide the 'Competitor Locations'?\", \"Could you please provide the 'Commercial Real Estate Cost Data'?\", \"Could you please provide the 'Traffic Pattern Data'?\", \"Could you please provide the 'Target Geographic Area Definition (e.g., Seattle boundary)'?\"]\n",
            "  Input Answers: ['Dataset (e.g., GeoJSON, CSV grid) or API endpoint for the target area', 'List of competitor addresses or geocoordinates', 'Dataset (e.g., price per sqft by zone) or API endpoint for the target area', 'Dataset (e.g., road network congestion) or API endpoint for the target area', 'SimulatedData_NotFound_For_Target Geographic Ar']\n",
            "    Updating/Adding key 'population_density_data' with value 'Dataset (e.g., GeoJSON, CSV grid) or API endpoint for the target area'\n",
            "      (Storing potential file path/source as string)\n",
            "    Updating/Adding key 'competitor_locations' with value 'List of competitor addresses or geocoordinates'\n",
            "    Updating/Adding key 'commercial_real_estate_cost_data' with value 'Dataset (e.g., price per sqft by zone) or API endpoint for the target area'\n",
            "      (Storing potential file path/source as string)\n",
            "    Updating/Adding key 'traffic_pattern_data' with value 'Dataset (e.g., road network congestion) or API endpoint for the target area'\n",
            "      (Storing potential file path/source as string)\n",
            "    Updating/Adding key 'target_geographic_area_definition_(e.g.,_seattle_boundary)' with value 'SimulatedData_NotFound_For_Target Geographic Ar'\n",
            "  Output Updated Data Keys: ['num_new_shops', 'min_distance_miles', 'population_density_data', 'competitor_locations', 'commercial_real_estate_cost_data', 'traffic_pattern_data', 'target_geographic_area_definition_(e.g.,_seattle_boundary)']\n",
            "Step 4.4: Exiting Update Data Based on Answers.\n",
            "Pipeline Update: Data updated with answers.\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: FACILITY_LOCATION_SEATTLE\n",
            "  Current Keys: ['num_new_shops', 'min_distance_miles', 'population_density_data', 'competitor_locations', 'commercial_real_estate_cost_data', 'traffic_pattern_data', 'target_geographic_area_definition_(e.g.,_seattle_boundary)']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['Target Geographic Area Definition (e.g., Seattle boundary)'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Error: Could not gather/simulate all required Simulation info.\n",
            "  Remaining: ['Target Geographic Area Definition (e.g., Seattle boundary)']\n",
            "\n",
            "--- Problem 4 Preparation Failed or Not Confirmed ---\n",
            "<<<<<<<<<< Finished Problem Index 4 >>>>>>>>>>\n",
            "\n",
            "\n",
            "<<<<<<<<<< Processing Problem Index 5 >>>>>>>>>>\n",
            "Description: 'I need to schedule 25 nurses across 3 shifts at Massachusetts General Hospital, considering their sh...'\n",
            "\n",
            "Starting Preparation Pipeline...\n",
            "\n",
            "=== Step 1: Problem Categorization ===\n",
            "\n",
            "Step 1.1: Entering LLM Categorization...\n",
            "  Analyzing Full Input Description (Length: 209):\n",
            "  'I need to schedule 25 nurses across 3 shifts at Massachusetts General Hospital, considering their shift preferences, required skill levels for each ward, and ensuring no one works more than 5 consecutive days.'\n",
            "  [LLM Placeholder Rule Match] NURSE_SCHEDULING_MGH keywords matched.\n",
            "  [LLM Placeholder] Final Categorization: NURSE_SCHEDULING_MGH\n",
            "Step 1.1: Exiting LLM Categorization.\n",
            "Pipeline Update: Problem categorized as NURSE_SCHEDULING_MGH\n",
            "\n",
            "=== Step 2: Initial Extraction / Automatic Data Fetching ===\n",
            "\n",
            "Step 2.1: Entering LLM Initial Data Extraction...\n",
            "  Problem Type: NURSE_SCHEDULING_MGH\n",
            "  [LLM Placeholder] Extracted Num Nurses: 25\n",
            "  [LLM Placeholder] Extracted Num Shifts: 3\n",
            "  Output Extracted Data: {'num_nurses': 25, 'num_shifts': 3}\n",
            "Step 2.1: Exiting LLM Initial Data Extraction.\n",
            "Pipeline Update: Initial data extracted: ['num_nurses', 'num_shifts']\n",
            "Pipeline Info: No automatic data fetching configured for this problem type in Step 2.\n",
            "\n",
            "=== Step 3 & 4: Manual Data Refinement / Simulation ===\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: NURSE_SCHEDULING_MGH\n",
            "  Current Keys: ['num_nurses', 'num_shifts']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['List of Nurses with Qualifications/Preferences', 'Ward Staffing Requirements per Shift', 'Labor Regulations (Consecutive days, hours/week)'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: Manual data required for: ['List of Nurses with Qualifications/Preferences', 'Ward Staffing Requirements per Shift', 'Labor Regulations (Consecutive days, hours/week)']\n",
            "\n",
            "--- Starting Simulation Loop ---\n",
            "--- Simulation Attempt 1 ---\n",
            "\n",
            "Step 4.2: Entering LLM Generate Questions...\n",
            "  Input Missing Info: ['List of Nurses with Qualifications/Preferences', 'Ward Staffing Requirements per Shift', 'Labor Regulations (Consecutive days, hours/week)']\n",
            "  [LLM Placeholder] Generated questions: [\"Could you please provide the 'List of Nurses with Qualifications/Preferences'?\", \"Could you please provide the 'Ward Staffing Requirements per Shift'?\", \"Could you please provide the 'Labor Regulations (Consecutive days, hours/week)'?\"] (using simple logic)\n",
            "Step 4.2: Exiting LLM Generate Questions.\n",
            "Pipeline Action: Simulating answers based on requirements CSV...\n",
            "    Found sim data for 'List of Nurses with Qualifications/Preferences': Using -> 'CSV or JSON list: [{'name':'Alice', 'qual':['RN','ICU'], 'prefs':['Day','No_Weekend']}, ...]'\n",
            "    Found sim data for 'Ward Staffing Requirements per Shift': Using -> 'JSON/Dict: {'ICU': {'Day':{'RN':2,'CNA':1}, 'Night':{...}}, 'ER':{...}}'\n",
            "    Warning: No sim data found matching 'Labor Regulations (Consecutive days, hours/week)' for 'Nurse Scheduling Problem'.\n",
            "Pipeline Info: Simulated answers obtained: [\"CSV or JSON list: [{'name':'Alice', 'qual':['RN','ICU'], 'prefs':['Day','No_Weekend']}, ...]\", \"JSON/Dict: {'ICU': {'Day':{'RN':2,'CNA':1}, 'Night':{...}}, 'ER':{...}}\", 'SimulatedData_NotFound_For_Labor Regulations (C']\n",
            "\n",
            "Step 4.4: Entering Update Data Based on Answers...\n",
            "  Input Questions: [\"Could you please provide the 'List of Nurses with Qualifications/Preferences'?\", \"Could you please provide the 'Ward Staffing Requirements per Shift'?\", \"Could you please provide the 'Labor Regulations (Consecutive days, hours/week)'?\"]\n",
            "  Input Answers: [\"CSV or JSON list: [{'name':'Alice', 'qual':['RN','ICU'], 'prefs':['Day','No_Weekend']}, ...]\", \"JSON/Dict: {'ICU': {'Day':{'RN':2,'CNA':1}, 'Night':{...}}, 'ER':{...}}\", 'SimulatedData_NotFound_For_Labor Regulations (C']\n",
            "    Updating/Adding key 'list_of_nurses_with_qualifications/preferences' with value 'CSV or JSON list: [{'name':'Alice', 'qual':['RN','ICU'], 'prefs':['Day','No_Weekend']}, ...]'\n",
            "      (Could not parse answer as JSON list/dict, storing as string)\n",
            "    Updating/Adding key 'ward_staffing_requirements_per_shift' with value 'JSON/Dict: {'ICU': {'Day':{'RN':2,'CNA':1}, 'Night':{...}}, 'ER':{...}}'\n",
            "    Updating/Adding key 'labor_regulations_consecutive_days' with value 'SimulatedData_NotFound_For_Labor Regulations (C'\n",
            "  Output Updated Data Keys: ['num_nurses', 'num_shifts', 'list_of_nurses_with_qualifications/preferences', 'ward_staffing_requirements_per_shift', 'labor_regulations_consecutive_days']\n",
            "Step 4.4: Exiting Update Data Based on Answers.\n",
            "Pipeline Update: Data updated with answers.\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: NURSE_SCHEDULING_MGH\n",
            "  Current Keys: ['num_nurses', 'num_shifts', 'list_of_nurses_with_qualifications/preferences', 'ward_staffing_requirements_per_shift', 'labor_regulations_consecutive_days']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['List of Nurses with Qualifications/Preferences'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Error: Could not gather/simulate all required Simulation info.\n",
            "  Remaining: ['List of Nurses with Qualifications/Preferences']\n",
            "\n",
            "--- Problem 5 Preparation Failed or Not Confirmed ---\n",
            "<<<<<<<<<< Finished Problem Index 5 >>>>>>>>>>\n",
            "\n",
            "\n",
            "<<<<<<<<<< Processing Problem Index 6 >>>>>>>>>>\n",
            "Description: 'I need to invest $50,000 across stocks from the S&P 500, bonds, and ETFs to maximize returns with a ...'\n",
            "\n",
            "Starting Preparation Pipeline...\n",
            "\n",
            "=== Step 1: Problem Categorization ===\n",
            "\n",
            "Step 1.1: Entering LLM Categorization...\n",
            "  Analyzing Full Input Description (Length: 174):\n",
            "  'I need to invest $50,000 across stocks from the S&P 500, bonds, and ETFs to maximize returns with a risk level I'm comfortable with and proper diversification across sectors.'\n",
            "  [LLM Placeholder Rule Match] PORTFOLIO_OPTIMIZATION keywords matched.\n",
            "  [LLM Placeholder] Final Categorization: PORTFOLIO_OPTIMIZATION\n",
            "Step 1.1: Exiting LLM Categorization.\n",
            "Pipeline Update: Problem categorized as PORTFOLIO_OPTIMIZATION\n",
            "\n",
            "=== Step 2: Initial Extraction / Automatic Data Fetching ===\n",
            "\n",
            "Step 2.1: Entering LLM Initial Data Extraction...\n",
            "  Problem Type: PORTFOLIO_OPTIMIZATION\n",
            "  [LLM Placeholder] Extracted Investment Amount: 50000.0\n",
            "  Output Extracted Data: {'investment_amount': 50000.0}\n",
            "Step 2.1: Exiting LLM Initial Data Extraction.\n",
            "Pipeline Update: Initial data extracted: ['investment_amount']\n",
            "Pipeline Info: No automatic data fetching configured for this problem type in Step 2.\n",
            "\n",
            "=== Step 3 & 4: Manual Data Refinement / Simulation ===\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: PORTFOLIO_OPTIMIZATION\n",
            "  Current Keys: ['investment_amount']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['List of Potential Assets (Stocks, Bonds, ETFs)', 'Risk Level Preference', 'Diversification Rules', 'Historical Asset Performance Data (Prices/Returns)', 'Asset Sector Classifications', 'Asset Volatility Metrics', 'Asset Correlation Data'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: Manual data required for: ['List of Potential Assets (Stocks, Bonds, ETFs)', 'Risk Level Preference', 'Diversification Rules', 'Historical Asset Performance Data (Prices/Returns)', 'Asset Sector Classifications', 'Asset Volatility Metrics', 'Asset Correlation Data']\n",
            "\n",
            "--- Starting Simulation Loop ---\n",
            "--- Simulation Attempt 1 ---\n",
            "\n",
            "Step 4.2: Entering LLM Generate Questions...\n",
            "  Input Missing Info: ['List of Potential Assets (Stocks, Bonds, ETFs)', 'Risk Level Preference', 'Diversification Rules', 'Historical Asset Performance Data (Prices/Returns)', 'Asset Sector Classifications', 'Asset Volatility Metrics', 'Asset Correlation Data']\n",
            "  [LLM Placeholder] Generated questions: [\"Could you please provide the 'List of Potential Assets (Stocks, Bonds, ETFs)'?\", \"Could you please provide the 'Risk Level Preference'?\", \"Could you please provide the 'Diversification Rules'?\", \"Could you please provide the 'Historical Asset Performance Data (Prices/Returns)'?\", \"Could you please provide the 'Asset Sector Classifications'?\", \"Could you please provide the 'Asset Volatility Metrics'?\", \"Could you please provide the 'Asset Correlation Data'?\"] (using simple logic)\n",
            "Step 4.2: Exiting LLM Generate Questions.\n",
            "Pipeline Action: Simulating answers based on requirements CSV...\n",
            "    Warning: No sim data found matching 'List of Potential Assets (Stocks, Bonds, ETFs)' for 'Portfolio Optimization'.\n",
            "    Found sim data for 'Risk Level Preference': Using -> 'Categorical description: 'low', 'medium', 'high''\n",
            "    Found sim data for 'Diversification Rules': Using -> 'Description or constraints: 'Max 10% per sector', 'Min 5 assets''\n",
            "    Warning: No sim data found matching 'Historical Asset Performance Data (Prices/Returns)' for 'Portfolio Optimization'.\n",
            "    Found sim data for 'Asset Sector Classifications': Using -> 'Mapping from asset to sector: {'AAPL':'Technology', 'AGG':'Bond', ...}'\n",
            "    Found sim data for 'Asset Volatility Metrics': Using -> 'Calculated values (e.g., standard deviation) or API endpoint'\n",
            "    Found sim data for 'Asset Correlation Data': Using -> 'Correlation Matrix (CSV/JSON)'\n",
            "Pipeline Info: Simulated answers obtained: ['SimulatedData_NotFound_For_List of Potential As', \"Categorical description: 'low', 'medium', 'high'\", \"Description or constraints: 'Max 10% per sector', 'Min 5 assets'\", 'SimulatedData_NotFound_For_Historical Asset Per', \"Mapping from asset to sector: {'AAPL':'Technology', 'AGG':'Bond', ...}\", 'Calculated values (e.g., standard deviation) or API endpoint', 'Correlation Matrix (CSV/JSON)']\n",
            "\n",
            "Step 4.4: Entering Update Data Based on Answers...\n",
            "  Input Questions: [\"Could you please provide the 'List of Potential Assets (Stocks, Bonds, ETFs)'?\", \"Could you please provide the 'Risk Level Preference'?\", \"Could you please provide the 'Diversification Rules'?\", \"Could you please provide the 'Historical Asset Performance Data (Prices/Returns)'?\", \"Could you please provide the 'Asset Sector Classifications'?\", \"Could you please provide the 'Asset Volatility Metrics'?\", \"Could you please provide the 'Asset Correlation Data'?\"]\n",
            "  Input Answers: ['SimulatedData_NotFound_For_List of Potential As', \"Categorical description: 'low', 'medium', 'high'\", \"Description or constraints: 'Max 10% per sector', 'Min 5 assets'\", 'SimulatedData_NotFound_For_Historical Asset Per', \"Mapping from asset to sector: {'AAPL':'Technology', 'AGG':'Bond', ...}\", 'Calculated values (e.g., standard deviation) or API endpoint', 'Correlation Matrix (CSV/JSON)']\n",
            "    Updating/Adding key 'list_of_potential_assets' with value 'SimulatedData_NotFound_For_List of Potential As'\n",
            "    Updating/Adding key 'risk_level_preference' with value 'Categorical description: 'low', 'medium', 'high''\n",
            "    Updating/Adding key 'diversification_rules' with value 'Description or constraints: 'Max 10% per sector', 'Min 5 assets''\n",
            "    Updating/Adding key 'historical_asset_performance_data' with value 'SimulatedData_NotFound_For_Historical Asset Per'\n",
            "      (Storing potential file path/source as string)\n",
            "    Updating/Adding key 'asset_sector_classifications' with value 'Mapping from asset to sector: {'AAPL':'Technology', 'AGG':'Bond', ...}'\n",
            "    Updating/Adding key 'asset_volatility_metrics' with value 'Calculated values (e.g., standard deviation) or API endpoint'\n",
            "    Updating/Adding key 'asset_correlation_data' with value 'Correlation Matrix (CSV/JSON)'\n",
            "      (Storing potential file path/source as string)\n",
            "  Output Updated Data Keys: ['investment_amount', 'list_of_potential_assets', 'risk_level_preference', 'diversification_rules', 'historical_asset_performance_data', 'asset_sector_classifications', 'asset_volatility_metrics', 'asset_correlation_data']\n",
            "Step 4.4: Exiting Update Data Based on Answers.\n",
            "Pipeline Update: Data updated with answers.\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: PORTFOLIO_OPTIMIZATION\n",
            "  Current Keys: ['investment_amount', 'list_of_potential_assets', 'risk_level_preference', 'diversification_rules', 'historical_asset_performance_data', 'asset_sector_classifications', 'asset_volatility_metrics', 'asset_correlation_data']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: [] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: All essential info seems gathered/simulated.\n",
            "--- End Simulation Loop ---\n",
            "\n",
            "=== Step 5: Post-Processing ===\n",
            "\n",
            "Step 5: Entering Geocoding (if needed)...\n",
            "  No suitable location list/string found for geocoding or data type incorrect.\n",
            "Step 5: Exiting Geocoding.\n",
            "\n",
            "=== Step 6: Final Confirmation ===\n",
            "\n",
            "Step 6: Entering Present Data for Confirmation...\n",
            "  Identified Problem Type: PORTFOLIO_OPTIMIZATION\n",
            "  Collected & Prepared Data:\n",
            "{\n",
            "  \"investment_amount\": 50000.0,\n",
            "  \"list_of_potential_assets\": \"SimulatedData_NotFound_For_List of Potential As\",\n",
            "  \"risk_level_preference\": \"Categorical description: 'low', 'medium', 'high'\",\n",
            "  \"diversification_rules\": \"Description or constraints: 'Max 10% per sector', 'Min 5 assets'\",\n",
            "  \"historical_asset_performance_data\": \"SimulatedData_NotFound_For_Historical Asset Per\",\n",
            "  \"asset_sector_classifications\": \"Mapping from asset to sector: {'AAPL':'Technology', 'AGG':'Bond', ...}\",\n",
            "  \"asset_volatility_metrics\": \"Calculated values (e.g., standard deviation) or API endpoint\",\n",
            "  \"asset_correlation_data\": \"Correlation Matrix (CSV/JSON)\"\n",
            "}\n",
            "  > Is the above problem formulation correct...?: yes (Simulated)\n",
            "  User confirmation status: True\n",
            "Step 6: Exiting Present Data for Confirmation.\n",
            "\n",
            "Preparation Pipeline Completed Successfully.\n",
            "\n",
            "--- Problem 6 Preparation Complete ---\n",
            "  Type: PORTFOLIO_OPTIMIZATION\n",
            "  Final Prepared Data (JSON):\n",
            "{\n",
            "  \"investment_amount\": 50000.0,\n",
            "  \"list_of_potential_assets\": \"SimulatedData_NotFound_For_List of Potential As\",\n",
            "  \"risk_level_preference\": \"Categorical description: 'low', 'medium', 'high'\",\n",
            "  \"diversification_rules\": \"Description or constraints: 'Max 10% per sector', 'Min 5 assets'\",\n",
            "  \"historical_asset_performance_data\": \"SimulatedData_NotFound_For_Historical Asset Per\",\n",
            "  \"asset_sector_classifications\": \"Mapping from asset to sector: {'AAPL':'Technology', 'AGG':'Bond', ...}\",\n",
            "  \"asset_volatility_metrics\": \"Calculated values (e.g., standard deviation) or API endpoint\",\n",
            "  \"asset_correlation_data\": \"Correlation Matrix (CSV/JSON)\"\n",
            "}\n",
            "\n",
            "[Placeholder] Would proceed to EvoMoE stage for this problem now...\n",
            "<<<<<<<<<< Finished Problem Index 6 >>>>>>>>>>\n",
            "\n",
            "\n",
            "<<<<<<<<<< Processing Problem Index 7 >>>>>>>>>>\n",
            "Description: 'I'm organizing a conference at the Hilton Chicago with 35 sessions across 8 rooms over 3 days. I nee...'\n",
            "\n",
            "Starting Preparation Pipeline...\n",
            "\n",
            "=== Step 1: Problem Categorization ===\n",
            "\n",
            "Step 1.1: Entering LLM Categorization...\n",
            "  Analyzing Full Input Description (Length: 212):\n",
            "  'I'm organizing a conference at the Hilton Chicago with 35 sessions across 8 rooms over 3 days. I need to schedule them to minimize room changes for topic tracks and avoid scheduling similar topics simultaneously.'\n",
            "  [LLM Placeholder Rule Match] TIMETABLING_CONFERENCE keywords matched.\n",
            "  [LLM Placeholder] Final Categorization: TIMETABLING_CONFERENCE\n",
            "Step 1.1: Exiting LLM Categorization.\n",
            "Pipeline Update: Problem categorized as TIMETABLING_CONFERENCE\n",
            "\n",
            "=== Step 2: Initial Extraction / Automatic Data Fetching ===\n",
            "\n",
            "Step 2.1: Entering LLM Initial Data Extraction...\n",
            "  Problem Type: TIMETABLING_CONFERENCE\n",
            "  [LLM Placeholder] Extracted Num Sessions: 35\n",
            "  [LLM Placeholder] Extracted Num Rooms: 8\n",
            "  [LLM Placeholder] Extracted Num Days: 3\n",
            "  Output Extracted Data: {'num_sessions': 35, 'num_rooms': 8, 'num_days': 3}\n",
            "Step 2.1: Exiting LLM Initial Data Extraction.\n",
            "Pipeline Update: Initial data extracted: ['num_sessions', 'num_rooms', 'num_days']\n",
            "Pipeline Info: No automatic data fetching configured for this problem type in Step 2.\n",
            "\n",
            "=== Step 3 & 4: Manual Data Refinement / Simulation ===\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: TIMETABLING_CONFERENCE\n",
            "  Current Keys: ['num_sessions', 'num_rooms', 'num_days']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['List of Sessions with Topics/Speakers', 'List of Rooms with Capacities', 'Timeslots per Day', 'Speaker Availability Constraints', 'Topic Relationships (Minimize distance/conflict)', 'Predicted Attendance per Session (Optional)'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: Manual data required for: ['List of Sessions with Topics/Speakers', 'List of Rooms with Capacities', 'Timeslots per Day', 'Speaker Availability Constraints', 'Topic Relationships (Minimize distance/conflict)', 'Predicted Attendance per Session (Optional)']\n",
            "\n",
            "--- Starting Simulation Loop ---\n",
            "--- Simulation Attempt 1 ---\n",
            "\n",
            "Step 4.2: Entering LLM Generate Questions...\n",
            "  Input Missing Info: ['List of Sessions with Topics/Speakers', 'List of Rooms with Capacities', 'Timeslots per Day', 'Speaker Availability Constraints', 'Topic Relationships (Minimize distance/conflict)', 'Predicted Attendance per Session (Optional)']\n",
            "  [LLM Placeholder] Generated questions: [\"Could you please provide the 'List of Sessions with Topics/Speakers'?\", \"Could you please provide the 'List of Rooms with Capacities'?\", \"Could you please provide the 'Timeslots per Day'?\", \"Could you please provide the 'Speaker Availability Constraints'?\", \"Could you please provide the 'Topic Relationships (Minimize distance/conflict)'?\", \"Could you please provide the 'Predicted Attendance per Session (Optional)'?\"] (using simple logic)\n",
            "Step 4.2: Exiting LLM Generate Questions.\n",
            "Pipeline Action: Simulating answers based on requirements CSV...\n",
            "    Found sim data for 'List of Sessions with Topics/Speakers': Using -> 'CSV or JSON list: [{'session_id':1, 'title':'Intro to EA', 'speaker':'Dr. X', 'topic':'EA Basics'}, ...]'\n",
            "    Found sim data for 'List of Rooms with Capacities': Using -> 'CSV or JSON list: [{'room_name':'Room A', 'capacity':50}, ...]'\n",
            "    Found sim data for 'Timeslots per Day': Using -> 'Integer or list of start/end times'\n",
            "    Found sim data for 'Speaker Availability Constraints': Using -> 'JSON/Dict: {'Dr. X': ['Day1_Morning', 'Day2_All'], ...}'\n",
            "    Warning: No sim data found matching 'Topic Relationships (Minimize distance/conflict)' for 'Timetabling Problem'.\n",
            "    Warning: No sim data found matching 'Predicted Attendance per Session (Optional)' for 'Timetabling Problem'.\n",
            "Pipeline Info: Simulated answers obtained: [\"CSV or JSON list: [{'session_id':1, 'title':'Intro to EA', 'speaker':'Dr. X', 'topic':'EA Basics'}, ...]\", \"CSV or JSON list: [{'room_name':'Room A', 'capacity':50}, ...]\", 'Integer or list of start/end times', \"JSON/Dict: {'Dr. X': ['Day1_Morning', 'Day2_All'], ...}\", 'SimulatedData_NotFound_For_Topic Relationships ', 'SimulatedData_NotFound_For_Predicted Attendance']\n",
            "\n",
            "Step 4.4: Entering Update Data Based on Answers...\n",
            "  Input Questions: [\"Could you please provide the 'List of Sessions with Topics/Speakers'?\", \"Could you please provide the 'List of Rooms with Capacities'?\", \"Could you please provide the 'Timeslots per Day'?\", \"Could you please provide the 'Speaker Availability Constraints'?\", \"Could you please provide the 'Topic Relationships (Minimize distance/conflict)'?\", \"Could you please provide the 'Predicted Attendance per Session (Optional)'?\"]\n",
            "  Input Answers: [\"CSV or JSON list: [{'session_id':1, 'title':'Intro to EA', 'speaker':'Dr. X', 'topic':'EA Basics'}, ...]\", \"CSV or JSON list: [{'room_name':'Room A', 'capacity':50}, ...]\", 'Integer or list of start/end times', \"JSON/Dict: {'Dr. X': ['Day1_Morning', 'Day2_All'], ...}\", 'SimulatedData_NotFound_For_Topic Relationships ', 'SimulatedData_NotFound_For_Predicted Attendance']\n",
            "    Updating/Adding key 'list_of_sessions_with_topics_speakers' with value 'CSV or JSON list: [{'session_id':1, 'title':'Intro to EA', 'speaker':'Dr. X', 'topic':'EA Basics'}, ...]'\n",
            "      (Could not parse answer as JSON list/dict, storing as string)\n",
            "    Updating/Adding key 'list_of_rooms_with_capacities' with value 'CSV or JSON list: [{'room_name':'Room A', 'capacity':50}, ...]'\n",
            "      (Could not parse answer as JSON list/dict, storing as string)\n",
            "    Updating/Adding key 'timeslots_per_day' with value 'Integer or list of start/end times'\n",
            "    Updating/Adding key 'speaker_availability_constraints' with value 'JSON/Dict: {'Dr. X': ['Day1_Morning', 'Day2_All'], ...}'\n",
            "      (Could not parse answer as JSON list/dict, storing as string)\n",
            "    Updating/Adding key 'topic_relationships_minimize_distance_conflict' with value 'SimulatedData_NotFound_For_Topic Relationships '\n",
            "    Updating/Adding key 'predicted_attendance_per_session_optional' with value 'SimulatedData_NotFound_For_Predicted Attendance'\n",
            "  Output Updated Data Keys: ['num_sessions', 'num_rooms', 'num_days', 'list_of_sessions_with_topics_speakers', 'list_of_rooms_with_capacities', 'timeslots_per_day', 'speaker_availability_constraints', 'topic_relationships_minimize_distance_conflict', 'predicted_attendance_per_session_optional']\n",
            "Step 4.4: Exiting Update Data Based on Answers.\n",
            "Pipeline Update: Data updated with answers.\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: TIMETABLING_CONFERENCE\n",
            "  Current Keys: ['num_sessions', 'num_rooms', 'num_days', 'list_of_sessions_with_topics_speakers', 'list_of_rooms_with_capacities', 'timeslots_per_day', 'speaker_availability_constraints', 'topic_relationships_minimize_distance_conflict', 'predicted_attendance_per_session_optional']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: [] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: All essential info seems gathered/simulated.\n",
            "--- End Simulation Loop ---\n",
            "\n",
            "=== Step 5: Post-Processing ===\n",
            "\n",
            "Step 5: Entering Geocoding (if needed)...\n",
            "  No suitable location list/string found for geocoding or data type incorrect.\n",
            "Step 5: Exiting Geocoding.\n",
            "\n",
            "=== Step 6: Final Confirmation ===\n",
            "\n",
            "Step 6: Entering Present Data for Confirmation...\n",
            "  Identified Problem Type: TIMETABLING_CONFERENCE\n",
            "  Collected & Prepared Data:\n",
            "{\n",
            "  \"num_sessions\": 35,\n",
            "  \"num_rooms\": 8,\n",
            "  \"num_days\": 3,\n",
            "  \"list_of_sessions_with_topics_speakers\": \"CSV or JSON list: [{'session_id':1, 'title':'Intro to EA', 'speaker':'Dr. X', 'topic':'EA Basics'}, ...]\",\n",
            "  \"list_of_rooms_with_capacities\": \"CSV or JSON list: [{'room_name':'Room A', 'capacity':50}, ...]\",\n",
            "  \"timeslots_per_day\": \"Integer or list of start/end times\",\n",
            "  \"speaker_availability_constraints\": \"JSON/Dict: {'Dr. X': ['Day1_Morning', 'Day2_All'], ...}\",\n",
            "  \"topic_relationships_minimize_distance_conflict\": \"SimulatedData_NotFound_For_Topic Relationships \",\n",
            "  \"predicted_attendance_per_session_optional\": \"SimulatedData_NotFound_For_Predicted Attendance\"\n",
            "}\n",
            "  > Is the above problem formulation correct...?: yes (Simulated)\n",
            "  User confirmation status: True\n",
            "Step 6: Exiting Present Data for Confirmation.\n",
            "\n",
            "Preparation Pipeline Completed Successfully.\n",
            "\n",
            "--- Problem 7 Preparation Complete ---\n",
            "  Type: TIMETABLING_CONFERENCE\n",
            "  Final Prepared Data (JSON):\n",
            "{\n",
            "  \"num_sessions\": 35,\n",
            "  \"num_rooms\": 8,\n",
            "  \"num_days\": 3,\n",
            "  \"list_of_sessions_with_topics_speakers\": \"CSV or JSON list: [{'session_id':1, 'title':'Intro to EA', 'speaker':'Dr. X', 'topic':'EA Basics'}, ...]\",\n",
            "  \"list_of_rooms_with_capacities\": \"CSV or JSON list: [{'room_name':'Room A', 'capacity':50}, ...]\",\n",
            "  \"timeslots_per_day\": \"Integer or list of start/end times\",\n",
            "  \"speaker_availability_constraints\": \"JSON/Dict: {'Dr. X': ['Day1_Morning', 'Day2_All'], ...}\",\n",
            "  \"topic_relationships_minimize_distance_conflict\": \"SimulatedData_NotFound_For_Topic Relationships \",\n",
            "  \"predicted_attendance_per_session_optional\": \"SimulatedData_NotFound_For_Predicted Attendance\"\n",
            "}\n",
            "\n",
            "[Placeholder] Would proceed to EvoMoE stage for this problem now...\n",
            "<<<<<<<<<< Finished Problem Index 7 >>>>>>>>>>\n",
            "\n",
            "\n",
            "<<<<<<<<<< Processing Problem Index 8 >>>>>>>>>>\n",
            "Description: 'I need to plan the construction sequence for our 50-story building in downtown Miami, determining th...'\n",
            "\n",
            "Starting Preparation Pipeline...\n",
            "\n",
            "=== Step 1: Problem Categorization ===\n",
            "\n",
            "Step 1.1: Entering LLM Categorization...\n",
            "  Analyzing Full Input Description (Length: 236):\n",
            "  'I need to plan the construction sequence for our 50-story building in downtown Miami, determining the optimal order of tasks considering crew availability, material delivery times, and weather forecasts to minimize the project timeline.'\n",
            "  [LLM Placeholder Rule Match] PROJECT_SCHEDULING_CONSTRUCTION keywords matched.\n",
            "  [LLM Placeholder] Final Categorization: PROJECT_SCHEDULING_CONSTRUCTION\n",
            "Step 1.1: Exiting LLM Categorization.\n",
            "Pipeline Update: Problem categorized as PROJECT_SCHEDULING_CONSTRUCTION\n",
            "\n",
            "=== Step 2: Initial Extraction / Automatic Data Fetching ===\n",
            "\n",
            "Step 2.1: Entering LLM Initial Data Extraction...\n",
            "  Problem Type: PROJECT_SCHEDULING_CONSTRUCTION\n",
            "  [LLM Placeholder] Extracted Building Stories: 50\n",
            "  Output Extracted Data: {'building_stories': 50}\n",
            "Step 2.1: Exiting LLM Initial Data Extraction.\n",
            "Pipeline Update: Initial data extracted: ['building_stories']\n",
            "Pipeline Info: No automatic data fetching configured for this problem type in Step 2.\n",
            "\n",
            "=== Step 3 & 4: Manual Data Refinement / Simulation ===\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: PROJECT_SCHEDULING_CONSTRUCTION\n",
            "  Current Keys: ['building_stories']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['List of Tasks with Durations and Dependencies', 'Crew Availability (Type and Count per Period)', 'Material Delivery Lead Times', 'Weather Forecast Source/Data'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: Manual data required for: ['List of Tasks with Durations and Dependencies', 'Crew Availability (Type and Count per Period)', 'Material Delivery Lead Times', 'Weather Forecast Source/Data']\n",
            "\n",
            "--- Starting Simulation Loop ---\n",
            "--- Simulation Attempt 1 ---\n",
            "\n",
            "Step 4.2: Entering LLM Generate Questions...\n",
            "  Input Missing Info: ['List of Tasks with Durations and Dependencies', 'Crew Availability (Type and Count per Period)', 'Material Delivery Lead Times', 'Weather Forecast Source/Data']\n",
            "  [LLM Placeholder] Generated questions: [\"Could you please provide the 'List of Tasks with Durations and Dependencies'?\", \"Could you please provide the 'Crew Availability (Type and Count per Period)'?\", \"Could you please provide the 'Material Delivery Lead Times'?\", \"Could you please provide the 'Weather Forecast Source/Data'?\"] (using simple logic)\n",
            "Step 4.2: Exiting LLM Generate Questions.\n",
            "Pipeline Action: Simulating answers based on requirements CSV...\n",
            "    Found sim data for 'List of Tasks with Durations and Dependencies': Using -> 'CSV or JSON list: [{'task_id':'A', 'duration_days':5, 'depends_on':[]}, {'task_id':'B', 'duration_days':3, 'depends_on':['A']}, ...]'\n",
            "    Warning: No sim data found matching 'Crew Availability (Type and Count per Period)' for 'Project Scheduling Problem'.\n",
            "    Found sim data for 'Material Delivery Lead Times': Using -> 'JSON/Dict: {'Concrete': 7, 'SteelBeams': 14, ...}'\n",
            "    Found sim data for 'Weather Forecast Source/Data': Using -> 'API endpoint/key or historical weather pattern data'\n",
            "Pipeline Info: Simulated answers obtained: [\"CSV or JSON list: [{'task_id':'A', 'duration_days':5, 'depends_on':[]}, {'task_id':'B', 'duration_days':3, 'depends_on':['A']}, ...]\", 'SimulatedData_NotFound_For_Crew Availability (T', \"JSON/Dict: {'Concrete': 7, 'SteelBeams': 14, ...}\", 'API endpoint/key or historical weather pattern data']\n",
            "\n",
            "Step 4.4: Entering Update Data Based on Answers...\n",
            "  Input Questions: [\"Could you please provide the 'List of Tasks with Durations and Dependencies'?\", \"Could you please provide the 'Crew Availability (Type and Count per Period)'?\", \"Could you please provide the 'Material Delivery Lead Times'?\", \"Could you please provide the 'Weather Forecast Source/Data'?\"]\n",
            "  Input Answers: [\"CSV or JSON list: [{'task_id':'A', 'duration_days':5, 'depends_on':[]}, {'task_id':'B', 'duration_days':3, 'depends_on':['A']}, ...]\", 'SimulatedData_NotFound_For_Crew Availability (T', \"JSON/Dict: {'Concrete': 7, 'SteelBeams': 14, ...}\", 'API endpoint/key or historical weather pattern data']\n",
            "    Updating/Adding key 'list_of_tasks_with_durations_and_dependencies' with value 'CSV or JSON list: [{'task_id':'A', 'duration_days':5, 'depends_on':[]}, {'task_id':'B', 'duration_days':3, 'depends_on':['A']}, ...]'\n",
            "      (Could not parse answer as JSON list/dict, storing as string)\n",
            "    Updating/Adding key 'crew_availability_type_and_count_per_period' with value 'SimulatedData_NotFound_For_Crew Availability (T'\n",
            "    Updating/Adding key 'material_delivery_lead_times' with value 'JSON/Dict: {'Concrete': 7, 'SteelBeams': 14, ...}'\n",
            "    Updating/Adding key 'weather_forecast_source_data' with value 'API endpoint/key or historical weather pattern data'\n",
            "      (Storing potential file path/source as string)\n",
            "  Output Updated Data Keys: ['building_stories', 'list_of_tasks_with_durations_and_dependencies', 'crew_availability_type_and_count_per_period', 'material_delivery_lead_times', 'weather_forecast_source_data']\n",
            "Step 4.4: Exiting Update Data Based on Answers.\n",
            "Pipeline Update: Data updated with answers.\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: PROJECT_SCHEDULING_CONSTRUCTION\n",
            "  Current Keys: ['building_stories', 'list_of_tasks_with_durations_and_dependencies', 'crew_availability_type_and_count_per_period', 'material_delivery_lead_times', 'weather_forecast_source_data']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: [] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: All essential info seems gathered/simulated.\n",
            "--- End Simulation Loop ---\n",
            "\n",
            "=== Step 5: Post-Processing ===\n",
            "\n",
            "Step 5: Entering Geocoding (if needed)...\n",
            "  No suitable location list/string found for geocoding or data type incorrect.\n",
            "Step 5: Exiting Geocoding.\n",
            "\n",
            "=== Step 6: Final Confirmation ===\n",
            "\n",
            "Step 6: Entering Present Data for Confirmation...\n",
            "  Identified Problem Type: PROJECT_SCHEDULING_CONSTRUCTION\n",
            "  Collected & Prepared Data:\n",
            "{\n",
            "  \"building_stories\": 50,\n",
            "  \"list_of_tasks_with_durations_and_dependencies\": \"CSV or JSON list: [{'task_id':'A', 'duration_days':5, 'depends_on':[]}, {'task_id':'B', 'duration_days':3, 'depends_on':['A']}, ...]\",\n",
            "  \"crew_availability_type_and_count_per_period\": \"SimulatedData_NotFound_For_Crew Availability (T\",\n",
            "  \"material_delivery_lead_times\": \"JSON/Dict: {'Concrete': 7, 'SteelBeams': 14, ...}\",\n",
            "  \"weather_forecast_source_data\": \"API endpoint/key or historical weather pattern data\"\n",
            "}\n",
            "  > Is the above problem formulation correct...?: yes (Simulated)\n",
            "  User confirmation status: True\n",
            "Step 6: Exiting Present Data for Confirmation.\n",
            "\n",
            "Preparation Pipeline Completed Successfully.\n",
            "\n",
            "--- Problem 8 Preparation Complete ---\n",
            "  Type: PROJECT_SCHEDULING_CONSTRUCTION\n",
            "  Final Prepared Data (JSON):\n",
            "{\n",
            "  \"building_stories\": 50,\n",
            "  \"list_of_tasks_with_durations_and_dependencies\": \"CSV or JSON list: [{'task_id':'A', 'duration_days':5, 'depends_on':[]}, {'task_id':'B', 'duration_days':3, 'depends_on':['A']}, ...]\",\n",
            "  \"crew_availability_type_and_count_per_period\": \"SimulatedData_NotFound_For_Crew Availability (T\",\n",
            "  \"material_delivery_lead_times\": \"JSON/Dict: {'Concrete': 7, 'SteelBeams': 14, ...}\",\n",
            "  \"weather_forecast_source_data\": \"API endpoint/key or historical weather pattern data\"\n",
            "}\n",
            "\n",
            "[Placeholder] Would proceed to EvoMoE stage for this problem now...\n",
            "<<<<<<<<<< Finished Problem Index 8 >>>>>>>>>>\n",
            "\n",
            "\n",
            "<<<<<<<<<< Processing Problem Index 9 >>>>>>>>>>\n",
            "Description: 'I need to design a water distribution network for a new development in Phoenix with 120 homes, deter...'\n",
            "\n",
            "Starting Preparation Pipeline...\n",
            "\n",
            "=== Step 1: Problem Categorization ===\n",
            "\n",
            "Step 1.1: Entering LLM Categorization...\n",
            "  Analyzing Full Input Description (Length: 208):\n",
            "  'I need to design a water distribution network for a new development in Phoenix with 120 homes, determining pipe diameters and pump capacities to ensure adequate pressure while minimizing infrastructure costs.'\n",
            "  [LLM Placeholder Rule Match] NETWORK_DESIGN_WATER keywords matched.\n",
            "  [LLM Placeholder] Final Categorization: NETWORK_DESIGN_WATER\n",
            "Step 1.1: Exiting LLM Categorization.\n",
            "Pipeline Update: Problem categorized as NETWORK_DESIGN_WATER\n",
            "\n",
            "=== Step 2: Initial Extraction / Automatic Data Fetching ===\n",
            "\n",
            "Step 2.1: Entering LLM Initial Data Extraction...\n",
            "  Problem Type: NETWORK_DESIGN_WATER\n",
            "  [LLM Placeholder] Extracted Num Homes: 120\n",
            "  Output Extracted Data: {'num_homes': 120}\n",
            "Step 2.1: Exiting LLM Initial Data Extraction.\n",
            "Pipeline Update: Initial data extracted: ['num_homes']\n",
            "Pipeline Info: No automatic data fetching configured for this problem type in Step 2.\n",
            "\n",
            "=== Step 3 & 4: Manual Data Refinement / Simulation ===\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: NETWORK_DESIGN_WATER\n",
            "  Current Keys: ['num_homes']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['Development Location/Area Definition', 'Elevation Data for Area', 'Water Demand Patterns (Per Home/Area, Peak/Avg)', 'Pipe Types and Costs (Per unit length per diameter)', 'Pump Types and Costs (Based on head/flow capacity)', 'Minimum Pressure Requirements at Nodes', 'Hydraulic Simulation Library/Tool'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Info: Manual data required for: ['Development Location/Area Definition', 'Elevation Data for Area', 'Water Demand Patterns (Per Home/Area, Peak/Avg)', 'Pipe Types and Costs (Per unit length per diameter)', 'Pump Types and Costs (Based on head/flow capacity)', 'Minimum Pressure Requirements at Nodes', 'Hydraulic Simulation Library/Tool']\n",
            "\n",
            "--- Starting Simulation Loop ---\n",
            "--- Simulation Attempt 1 ---\n",
            "\n",
            "Step 4.2: Entering LLM Generate Questions...\n",
            "  Input Missing Info: ['Development Location/Area Definition', 'Elevation Data for Area', 'Water Demand Patterns (Per Home/Area, Peak/Avg)', 'Pipe Types and Costs (Per unit length per diameter)', 'Pump Types and Costs (Based on head/flow capacity)', 'Minimum Pressure Requirements at Nodes', 'Hydraulic Simulation Library/Tool']\n",
            "  [LLM Placeholder] Generated questions: [\"Could you please provide the 'Development Location/Area Definition'?\", \"Could you please provide the 'Elevation Data for Area'?\", \"Could you please provide the 'Water Demand Patterns (Per Home/Area, Peak/Avg)'?\", \"Could you please provide the 'Pipe Types and Costs (Per unit length per diameter)'?\", \"Could you please provide the 'Pump Types and Costs (Based on head/flow capacity)'?\", \"Could you please provide the 'Minimum Pressure Requirements at Nodes'?\", \"Could you please provide the 'Hydraulic Simulation Library/Tool'?\"] (using simple logic)\n",
            "Step 4.2: Exiting LLM Generate Questions.\n",
            "Pipeline Action: Simulating answers based on requirements CSV...\n",
            "    Found sim data for 'Development Location/Area Definition': Using -> 'Coordinates or Boundary Polygon for Phoenix development'\n",
            "    Found sim data for 'Elevation Data for Area': Using -> 'Digital Elevation Model (DEM) file or API endpoint'\n",
            "    Warning: No sim data found matching 'Water Demand Patterns (Per Home/Area, Peak/Avg)' for 'Network Design Problem'.\n",
            "    Warning: No sim data found matching 'Pipe Types and Costs (Per unit length per diameter)' for 'Network Design Problem'.\n",
            "    Warning: No sim data found matching 'Pump Types and Costs (Based on head/flow capacity)' for 'Network Design Problem'.\n",
            "    Found sim data for 'Minimum Pressure Requirements at Nodes': Using -> 'Single value (e.g., PSI): 40'\n",
            "    Found sim data for 'Hydraulic Simulation Library/Tool': Using -> 'Name or reference to the simulation engine to be used (e.g., EPANET)'\n",
            "Pipeline Info: Simulated answers obtained: ['Coordinates or Boundary Polygon for Phoenix development', 'Digital Elevation Model (DEM) file or API endpoint', 'SimulatedData_NotFound_For_Water Demand Pattern', 'SimulatedData_NotFound_For_Pipe Types and Costs', 'SimulatedData_NotFound_For_Pump Types and Costs', 'Single value (e.g., PSI): 40', 'Name or reference to the simulation engine to be used (e.g., EPANET)']\n",
            "\n",
            "Step 4.4: Entering Update Data Based on Answers...\n",
            "  Input Questions: [\"Could you please provide the 'Development Location/Area Definition'?\", \"Could you please provide the 'Elevation Data for Area'?\", \"Could you please provide the 'Water Demand Patterns (Per Home/Area, Peak/Avg)'?\", \"Could you please provide the 'Pipe Types and Costs (Per unit length per diameter)'?\", \"Could you please provide the 'Pump Types and Costs (Based on head/flow capacity)'?\", \"Could you please provide the 'Minimum Pressure Requirements at Nodes'?\", \"Could you please provide the 'Hydraulic Simulation Library/Tool'?\"]\n",
            "  Input Answers: ['Coordinates or Boundary Polygon for Phoenix development', 'Digital Elevation Model (DEM) file or API endpoint', 'SimulatedData_NotFound_For_Water Demand Pattern', 'SimulatedData_NotFound_For_Pipe Types and Costs', 'SimulatedData_NotFound_For_Pump Types and Costs', 'Single value (e.g., PSI): 40', 'Name or reference to the simulation engine to be used (e.g., EPANET)']\n",
            "    Updating/Adding key 'development_location_area_definition' with value 'Coordinates or Boundary Polygon for Phoenix development'\n",
            "    Updating/Adding key 'route_elevation_data_source' with value 'Digital Elevation Model (DEM) file or API endpoint'\n",
            "      (Storing potential file path/source as string)\n",
            "    Updating/Adding key 'water_demand_patterns_per_home_area_peak_avg' with value 'SimulatedData_NotFound_For_Water Demand Pattern'\n",
            "    Updating/Adding key 'pipe_types_and_costs_per_unit_length_per_diameter' with value 'SimulatedData_NotFound_For_Pipe Types and Costs'\n",
            "    Updating/Adding key 'pump_types_and_costs_based_on_head_flow_capacity' with value 'SimulatedData_NotFound_For_Pump Types and Costs'\n",
            "    Updating/Adding key 'minimum_pressure_requirements_at_nodes' with value 'Single value (e.g., PSI): 40'\n",
            "    Updating/Adding key 'hydraulic_simulation_library_tool' with value 'Name or reference to the simulation engine to be used (e.g., EPANET)'\n",
            "  Output Updated Data Keys: ['num_homes', 'development_location_area_definition', 'route_elevation_data_source', 'water_demand_patterns_per_home_area_peak_avg', 'pipe_types_and_costs_per_unit_length_per_diameter', 'pump_types_and_costs_based_on_head_flow_capacity', 'minimum_pressure_requirements_at_nodes', 'hydraulic_simulation_library_tool']\n",
            "Step 4.4: Exiting Update Data Based on Answers.\n",
            "Pipeline Update: Data updated with answers.\n",
            "\n",
            "Step 3.1 / 4.1 (Re-check): Entering LLM Identify Missing Manual Info...\n",
            "  Problem Type: NETWORK_DESIGN_WATER\n",
            "  Current Keys: ['num_homes', 'development_location_area_definition', 'route_elevation_data_source', 'water_demand_patterns_per_home_area_peak_avg', 'pipe_types_and_costs_per_unit_length_per_diameter', 'pump_types_and_costs_based_on_head_flow_capacity', 'minimum_pressure_requirements_at_nodes', 'hydraulic_simulation_library_tool']\n",
            "  Auto Keys: []\n",
            "  [LLM Placeholder] Identified missing manual info: ['Elevation Data for Area'] (using improved rules)\n",
            "Step 3.1 / 4.1 (Re-check): Exiting LLM Identify Missing Manual Info.\n",
            "Pipeline Error: Could not gather/simulate all required Simulation info.\n",
            "  Remaining: ['Elevation Data for Area']\n",
            "\n",
            "--- Problem 9 Preparation Failed or Not Confirmed ---\n",
            "<<<<<<<<<< Finished Problem Index 9 >>>>>>>>>>\n",
            "\n",
            "\n",
            "--- All Problems Processed ---\n",
            "\n",
            "--- Final Analysis Table ---\n",
            "|   Index | Status            | Detected Type                   | Issues/Notes                          |\n",
            "|--------:|:------------------|:--------------------------------|:--------------------------------------|\n",
            "|       0 | Success           | TSP_FLIGHTS                     | Optional info sim data missing.       |\n",
            "|       1 | Success           | TSP_DRIVING_FUEL                | Completed successfully.               |\n",
            "|       2 | Success           | KNAPSACK_MOVING                 | Completed successfully.               |\n",
            "|       3 | Success           | VRP_MANHATTAN                   | Completed successfully.               |\n",
            "|       4 | FailedPreparation | Unknown                         | Pipeline failed or was not confirmed. |\n",
            "|       5 | FailedPreparation | Unknown                         | Pipeline failed or was not confirmed. |\n",
            "|       6 | Success           | PORTFOLIO_OPTIMIZATION          | Completed successfully.               |\n",
            "|       7 | Success           | TIMETABLING_CONFERENCE          | Completed successfully.               |\n",
            "|       8 | Success           | PROJECT_SCHEDULING_CONSTRUCTION | Completed successfully.               |\n",
            "|       9 | FailedPreparation | Unknown                         | Pipeline failed or was not confirmed. |\n",
            "--- End of Table ---\n",
            "\n",
            "--- Main Execution Block Finished ---\n"
          ]
        }
      ]
    }
  ]
}